{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Concrete Strength.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "paWTz67gLwxY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "420cd47b-da7f-41e9-e081-efab239734cf"
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.0)\n",
            "Requirement already satisfied: urllib3<1.23.0,>=1.15 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.10.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.2.6)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: Unidecode>=0.04.16 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.0.22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x240wcGZL1OH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9215ba7-e2c2-4c56-84e4-611b77153c77"
      },
      "cell_type": "code",
      "source": [
        "import io, os\n",
        "\n",
        "import googleapiclient.discovery\n",
        "import googleapiclient.http\n",
        "import google.colab\n",
        "\n",
        "def colab_kaggle_install_apikey():\n",
        "  \"\"\" \n",
        "  Copies 'kaggle.json' from Google Drive to Colaboratory environment\n",
        "  \n",
        "  Based on https://medium.com/@move37timm/using-kaggle-api-for-google-colaboratory-d18645f93648\n",
        "  \"\"\"\n",
        "  \n",
        "  google.colab.auth.authenticate_user()\n",
        "\n",
        "  drive_service = googleapiclient.discovery.build('drive', 'v3')\n",
        "  results = drive_service.files().list(q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "  kaggle_api_key = results.get('files', [])\n",
        "  if len(kaggle_api_key) == 0:\n",
        "    raise ValueError(\"Could not find kaggle.json in Google Drive\")\n",
        "\n",
        "  filename = \"/root/.kaggle/kaggle.json\"\n",
        "  os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "\n",
        "  request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "  fh = io.FileIO(filename, 'wb')\n",
        "  downloader = googleapiclient.http.MediaIoBaseDownload(fh, request)\n",
        "  done = False\n",
        "  while done is False:\n",
        "      status, done = downloader.next_chunk()\n",
        "  os.chmod(filename, 600)\n",
        "  print('Installed to {}'.format(filename))\n",
        "  \n",
        "colab_kaggle_install_apikey()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installed to /root/.kaggle/kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xxZKXQt8g60X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "166fa51d-f2f3-4636-f0cb-6ad52606bccd"
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c dat300-2018-concrete -p data/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Concrete_sampleSubmission.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Concrete_test.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Concrete_train.csv: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yjXtVMqphifK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "import pandas\n",
        "import numpy\n",
        "\n",
        "import sklearn\n",
        "\n",
        "import sklearn.preprocessing\n",
        "import sklearn.model_selection\n",
        "import sklearn.pipeline\n",
        "\n",
        "import sklearn.linear_model\n",
        "import sklearn.ensemble\n",
        "import sklearn.svm\n",
        "\n",
        "import keras\n",
        "import keras.wrappers.scikit_learn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rnDG8pJghzpY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "68ea4c01-6805-4e9c-be3c-e08ae66db6aa"
      },
      "cell_type": "code",
      "source": [
        "dataset = pandas.read_csv('data/Concrete_train.csv')\n",
        "target_column = 'ConcreteComp\n",
        "ressiveStrength'\n",
        "feature_columns = list(set(dataset.columns) - set([target_column]))\n",
        "\n",
        "dataset.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>BlastFurnaceSlag</th>\n",
              "      <th>FlyAsh</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>CoarseAggregate</th>\n",
              "      <th>FineAggregate</th>\n",
              "      <th>Age</th>\n",
              "      <th>ConcreteCompressiveStrength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>525.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>189.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1125.000000</td>\n",
              "      <td>613.000000</td>\n",
              "      <td>7</td>\n",
              "      <td>42.419998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>276.000000</td>\n",
              "      <td>116.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>180.000000</td>\n",
              "      <td>9.0</td>\n",
              "      <td>870.000000</td>\n",
              "      <td>768.000000</td>\n",
              "      <td>28</td>\n",
              "      <td>44.279999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>182.000000</td>\n",
              "      <td>45.200001</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>170.199997</td>\n",
              "      <td>8.2</td>\n",
              "      <td>1059.400024</td>\n",
              "      <td>780.700012</td>\n",
              "      <td>100</td>\n",
              "      <td>48.669998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>212.600006</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.400002</td>\n",
              "      <td>159.399994</td>\n",
              "      <td>10.4</td>\n",
              "      <td>1003.799988</td>\n",
              "      <td>903.799988</td>\n",
              "      <td>100</td>\n",
              "      <td>47.740002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>251.399994</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>118.300003</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>6.4</td>\n",
              "      <td>1028.400024</td>\n",
              "      <td>757.700012</td>\n",
              "      <td>100</td>\n",
              "      <td>44.209999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Cement  BlastFurnaceSlag      FlyAsh       Water  Superplasticizer  \\\n",
              "0  525.000000          0.000000    0.000000  189.000000               0.0   \n",
              "1  276.000000        116.000000   90.000000  180.000000               9.0   \n",
              "2  182.000000         45.200001  122.000000  170.199997               8.2   \n",
              "3  212.600006          0.000000  100.400002  159.399994              10.4   \n",
              "4  251.399994          0.000000  118.300003  188.500000               6.4   \n",
              "\n",
              "   CoarseAggregate  FineAggregate  Age  ConcreteCompressiveStrength  \n",
              "0      1125.000000     613.000000    7                    42.419998  \n",
              "1       870.000000     768.000000   28                    44.279999  \n",
              "2      1059.400024     780.700012  100                    48.669998  \n",
              "3      1003.799988     903.799988  100                    47.740002  \n",
              "4      1028.400024     757.700012  100                    44.209999  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "9fWr7doWmBVw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iAQC6MZRjMD8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1c59368d-e113-43ef-a7a2-d94ba5648b26"
      },
      "cell_type": "code",
      "source": [
        "compete = pandas.read_csv('data/Concrete_test.csv')\n",
        "compete.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>BlastFurnaceSlag</th>\n",
              "      <th>FlyAsh</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>CoarseAggregate</th>\n",
              "      <th>FineAggregate</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>540.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1125.000000</td>\n",
              "      <td>613.000000</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>314.000000</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>113.0</td>\n",
              "      <td>179.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>869.000000</td>\n",
              "      <td>690.000000</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>302.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>203.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>974.000000</td>\n",
              "      <td>817.000000</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>166.800003</td>\n",
              "      <td>250.199997</td>\n",
              "      <td>0.0</td>\n",
              "      <td>203.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>975.599976</td>\n",
              "      <td>692.599976</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>79.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>10.3</td>\n",
              "      <td>967.000000</td>\n",
              "      <td>712.000000</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Cement  BlastFurnaceSlag  FlyAsh  Water  Superplasticizer  \\\n",
              "0  540.000000          0.000000     0.0  173.0               0.0   \n",
              "1  314.000000        145.000000   113.0  179.0               8.0   \n",
              "2  302.000000          0.000000     0.0  203.0               0.0   \n",
              "3  166.800003        250.199997     0.0  203.5               0.0   \n",
              "4  446.000000         24.000000    79.0  162.0              10.3   \n",
              "\n",
              "   CoarseAggregate  FineAggregate  Age  \n",
              "0      1125.000000     613.000000   28  \n",
              "1       869.000000     690.000000   28  \n",
              "2       974.000000     817.000000   14  \n",
              "3       975.599976     692.599976    3  \n",
              "4       967.000000     712.000000   56  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "t2iKJYz4MIhD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/c/dat300-2018-concrete\n",
        "\n",
        "Keras to train a multilayer perceptron predicting the strength of the concrete.\n",
        "    \n",
        "        at least two types of activation functions\n",
        "        and use two different network complexities\n",
        "        (number of layers and number of hidden units in each of them).\n",
        "        \n",
        "        Compare and discuss (in a few senteces) ANN results\n",
        "        (performance and time consumption)\n",
        "        to results from linear regression method in scikit-learn\n",
        "        (with polynomials, for example linear, quadratic, cubic, etc.).\n",
        "\n",
        "        You can submit predictions to Kaggle from any of these models.\n",
        "\n",
        "\n",
        "* MLP: Two different architectures, two different activation functions\n",
        "* sklearn regression. PolynomialFeatures+Ridge, SVR rbf/poly"
      ]
    },
    {
      "metadata": {
        "id": "PVHmeEVkkShm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#test.shape, train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QCtj7AMgkZ_Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        " \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "95TZAqyApRA7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6425
        },
        "outputId": "d474dbcf-8121-4ffb-96d4-1aa94515f8aa"
      },
      "cell_type": "code",
      "source": [
        "# like sklearn.model_evaluation.cross_val_scores, but not requiring cloning of estimator\n",
        "def cv_scores(estimator, X, Y_true, cv=5, metric=None):\n",
        "  \n",
        "    if metric is None:\n",
        "      metric = sklearn.metrics.mean_absolute_error\n",
        "    \n",
        "    kf = sklearn.model_selection.KFold(n_splits=cv)\n",
        "\n",
        "    scores = []\n",
        "    for train_index, test_index in kf.split(X):\n",
        "      X_test = X[test_index]\n",
        "      Y_true_test = Y_true[test_index]\n",
        "      Y_pred = estimator.predict(X_test)\n",
        "      scores.append(metric(Y_true_test, Y_pred))\n",
        "      \n",
        "    return scores\n",
        "    \n",
        "\n",
        "def train_evaluate_model(dataset, model, gridparams, gridcv=5, evalcv=10, test_size=0.3, rng=1):\n",
        "  \n",
        "    scoring = 'neg_mean_absolute_error'\n",
        "  \n",
        "    X = dataset[feature_columns]\n",
        "    X = sklearn.preprocessing.RobustScaler().fit_transform(X)\n",
        "    \n",
        "    Y = dataset[target_column].values\n",
        "    X_train, X_test, Y_train, Y_test = \\\n",
        "      sklearn.model_selection.train_test_split(X, Y, test_size=test_size, random_state=rng)\n",
        "    \n",
        " \n",
        "    # Find hyperparameters\n",
        "    train_start = time.time()\n",
        "    if gridparams is not None:\n",
        "      grid = sklearn.model_selection.GridSearchCV(model, gridparams, cv=gridcv, scoring=scoring,\n",
        "                                                  iid=False, refit=True, return_train_score=True)\n",
        "      grid.fit(X_train, Y_train)\n",
        "      estimator = grid.best_estimator_\n",
        "      details = grid.cv_results_\n",
        "    else:\n",
        "      model.fit(X_train, Y_train)\n",
        "      estimator = model\n",
        "      details = {}\n",
        "    \n",
        "    train_time = time.time() - train_start\n",
        "    \n",
        "    # Evaluate   \n",
        "    evaluate_start = time.time()\n",
        "    test_scores = cv_scores(estimator, X_test, Y_test, cv=evalcv)\n",
        "    train_scores = cv_scores(estimator, X_train, Y_train, cv=evalcv)\n",
        "    evaluate_time =  time.time() - evaluate_start\n",
        "   \n",
        "    \n",
        "    return test_scores, train_scores, details, train_time, evaluate_time\n",
        "\n",
        "def build_mlp(layer_sizes, activation='relu'):\n",
        "    Dense = keras.layers.Dense\n",
        "  \n",
        "    model = keras.Sequential()\n",
        "    for i, size in enumerate(layer_sizes):\n",
        "      params = dict(activation=activation)\n",
        "      if i == 0:\n",
        "        params['input_dim'] = 8\n",
        "        model.add(Dense(layer_sizes[0], **params))  \n",
        "    model.add(Dense(1))\n",
        "    \n",
        "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
        "    \n",
        "    return model\n",
        "\n",
        "def KerasMLP(layer_sizes, activation):\n",
        "  def build_func():\n",
        "    return build_mlp(layer_sizes, activation)\n",
        "  return keras.wrappers.scikit_learn.KerasRegressor(build_func, epochs=50, batch_size=5, verbose=1)\n",
        "  \n",
        "def PolyRidge(degree):\n",
        "    m = sklearn.pipeline.make_pipeline(\n",
        "      sklearn.preprocessing.PolynomialFeatures(degree),\n",
        "      sklearn.linear_model.Ridge(),\n",
        "    )\n",
        "    return m\n",
        " \n",
        "C_params = numpy.geomspace(0.001, 1000.0, 50)\n",
        "A_params = numpy.geomspace(0.001, 1000.0, 50)\n",
        "\n",
        "models = {\n",
        "    'MLP 8-8 ReLu': ( KerasMLP([8,8],'relu'), None ),\n",
        "    'MLP 8-8 tanh': ( KerasMLP([8,8],'tanh'), None ),\n",
        "    'MLP 16-16 Relu': ( KerasMLP([16,16],'relu'), None ),\n",
        "    'Poly3-Ridge': ( PolyRidge(3) , { 'ridge__alpha': A_params }),\n",
        "    'Poly2-Ridge': ( PolyRidge(2) , { 'ridge__alpha': A_params }),\n",
        "    'RandomForest': ( sklearn.ensemble.RandomForestRegressor(n_estimators=50), {'min_samples_leaf': [1, 0.01, 0.03, 0.05, 0.10]}),\n",
        "    'SVM poly3': ( sklearn.svm.SVR(kernel='poly', degree=3), { 'C': C_params } ),\n",
        "    'SVM poly2': ( sklearn.svm.SVR(kernel='poly', degree=2), { 'C': C_params } ),\n",
        "    'SVM rbf': ( sklearn.svm.SVR(kernel='rbf', degree=2), { 'C': C_params } ),\n",
        "}\n",
        "\n",
        "results = []\n",
        "for i, model in enumerate(models.items()):\n",
        "    name, values = model\n",
        "    estimator, params = values\n",
        "    r = train_evaluate_model(dataset, estimator, params)\n",
        "    assert len(r) == 5, len(r)\n",
        "    print('r', i, r[3], r[4])\n",
        "    results.append((name, r))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "504/504 [==============================] - 5s 10ms/step - loss: 34.7997\n",
            "Epoch 2/50\n",
            "504/504 [==============================] - 0s 594us/step - loss: 34.0949\n",
            "Epoch 3/50\n",
            "504/504 [==============================] - 0s 600us/step - loss: 33.1242\n",
            "Epoch 4/50\n",
            "504/504 [==============================] - 0s 602us/step - loss: 31.7748\n",
            "Epoch 5/50\n",
            "504/504 [==============================] - 0s 602us/step - loss: 29.9881\n",
            "Epoch 6/50\n",
            "504/504 [==============================] - 0s 574us/step - loss: 27.7334\n",
            "Epoch 7/50\n",
            "504/504 [==============================] - 0s 566us/step - loss: 24.9422\n",
            "Epoch 8/50\n",
            "504/504 [==============================] - 0s 567us/step - loss: 21.8886\n",
            "Epoch 9/50\n",
            "504/504 [==============================] - 0s 575us/step - loss: 18.6908\n",
            "Epoch 10/50\n",
            "504/504 [==============================] - 0s 574us/step - loss: 15.7407\n",
            "Epoch 11/50\n",
            "504/504 [==============================] - 0s 587us/step - loss: 13.0532\n",
            "Epoch 12/50\n",
            "504/504 [==============================] - 0s 595us/step - loss: 10.9550\n",
            "Epoch 13/50\n",
            "504/504 [==============================] - 0s 655us/step - loss: 9.7320\n",
            "Epoch 14/50\n",
            "504/504 [==============================] - 0s 585us/step - loss: 9.0289\n",
            "Epoch 15/50\n",
            "504/504 [==============================] - 0s 591us/step - loss: 8.5566\n",
            "Epoch 16/50\n",
            "504/504 [==============================] - 0s 596us/step - loss: 8.2334\n",
            "Epoch 17/50\n",
            "504/504 [==============================] - 0s 594us/step - loss: 8.0375\n",
            "Epoch 18/50\n",
            "504/504 [==============================] - 0s 616us/step - loss: 7.9111\n",
            "Epoch 19/50\n",
            "504/504 [==============================] - 0s 601us/step - loss: 7.8146\n",
            "Epoch 20/50\n",
            "504/504 [==============================] - 0s 620us/step - loss: 7.7554\n",
            "Epoch 21/50\n",
            "504/504 [==============================] - 0s 621us/step - loss: 7.6957\n",
            "Epoch 22/50\n",
            "504/504 [==============================] - 0s 600us/step - loss: 7.6442\n",
            "Epoch 23/50\n",
            "504/504 [==============================] - 0s 615us/step - loss: 7.6019\n",
            "Epoch 24/50\n",
            "504/504 [==============================] - 0s 598us/step - loss: 7.5527\n",
            "Epoch 25/50\n",
            "504/504 [==============================] - 0s 563us/step - loss: 7.5036\n",
            "Epoch 26/50\n",
            "504/504 [==============================] - 0s 590us/step - loss: 7.4518\n",
            "Epoch 27/50\n",
            "504/504 [==============================] - 0s 582us/step - loss: 7.3982\n",
            "Epoch 28/50\n",
            "504/504 [==============================] - 0s 572us/step - loss: 7.3547\n",
            "Epoch 29/50\n",
            "504/504 [==============================] - 0s 586us/step - loss: 7.3150\n",
            "Epoch 30/50\n",
            "504/504 [==============================] - 0s 565us/step - loss: 7.2631\n",
            "Epoch 31/50\n",
            "504/504 [==============================] - 0s 559us/step - loss: 7.2098\n",
            "Epoch 32/50\n",
            "504/504 [==============================] - 0s 576us/step - loss: 7.1637\n",
            "Epoch 33/50\n",
            "504/504 [==============================] - 0s 586us/step - loss: 7.1254\n",
            "Epoch 34/50\n",
            "504/504 [==============================] - 0s 593us/step - loss: 7.0897\n",
            "Epoch 35/50\n",
            "504/504 [==============================] - 0s 590us/step - loss: 7.0565\n",
            "Epoch 36/50\n",
            "504/504 [==============================] - 0s 583us/step - loss: 7.0041\n",
            "Epoch 37/50\n",
            "504/504 [==============================] - 0s 560us/step - loss: 6.9804\n",
            "Epoch 38/50\n",
            "504/504 [==============================] - 0s 584us/step - loss: 6.9376\n",
            "Epoch 39/50\n",
            "504/504 [==============================] - 0s 585us/step - loss: 6.8995\n",
            "Epoch 40/50\n",
            "504/504 [==============================] - 0s 592us/step - loss: 6.8693\n",
            "Epoch 41/50\n",
            "504/504 [==============================] - 0s 606us/step - loss: 6.8275\n",
            "Epoch 42/50\n",
            "504/504 [==============================] - 0s 606us/step - loss: 6.7923\n",
            "Epoch 43/50\n",
            "504/504 [==============================] - 0s 619us/step - loss: 6.7454\n",
            "Epoch 44/50\n",
            "504/504 [==============================] - 0s 608us/step - loss: 6.7041\n",
            "Epoch 45/50\n",
            "504/504 [==============================] - 0s 600us/step - loss: 6.6717\n",
            "Epoch 46/50\n",
            "504/504 [==============================] - 0s 625us/step - loss: 6.6354\n",
            "Epoch 47/50\n",
            "504/504 [==============================] - 0s 595us/step - loss: 6.5872\n",
            "Epoch 48/50\n",
            "504/504 [==============================] - 0s 590us/step - loss: 6.5478\n",
            "Epoch 49/50\n",
            "504/504 [==============================] - 0s 601us/step - loss: 6.5068\n",
            "Epoch 50/50\n",
            "504/504 [==============================] - 0s 581us/step - loss: 6.4626\n",
            "22/22 [==============================] - 2s 89ms/step\n",
            "22/22 [==============================] - 0s 875us/step\n",
            "22/22 [==============================] - 0s 761us/step\n",
            "22/22 [==============================] - 0s 846us/step\n",
            "22/22 [==============================] - 0s 761us/step\n",
            "22/22 [==============================] - 0s 752us/step\n",
            "22/22 [==============================] - 0s 763us/step\n",
            "21/21 [==============================] - 0s 845us/step\n",
            "21/21 [==============================] - 0s 933us/step\n",
            "21/21 [==============================] - 0s 905us/step\n",
            "51/51 [==============================] - 0s 660us/step\n",
            "51/51 [==============================] - 0s 600us/step\n",
            "51/51 [==============================] - 0s 638us/step\n",
            "51/51 [==============================] - 0s 642us/step\n",
            "50/50 [==============================] - 0s 543us/step\n",
            "50/50 [==============================] - 0s 589us/step\n",
            "50/50 [==============================] - 0s 608us/step\n",
            "50/50 [==============================] - 0s 566us/step\n",
            "50/50 [==============================] - 0s 574us/step\n",
            "50/50 [==============================] - 0s 599us/step\n",
            "r 0 20.256496906280518 2.4626405239105225\n",
            "Epoch 1/50\n",
            "504/504 [==============================] - 5s 9ms/step - loss: 34.8824\n",
            "Epoch 2/50\n",
            "504/504 [==============================] - 0s 626us/step - loss: 34.1597\n",
            "Epoch 3/50\n",
            "504/504 [==============================] - 0s 587us/step - loss: 33.1777\n",
            "Epoch 4/50\n",
            "504/504 [==============================] - 0s 600us/step - loss: 31.8774\n",
            "Epoch 5/50\n",
            "504/504 [==============================] - 0s 639us/step - loss: 30.3567\n",
            "Epoch 6/50\n",
            "504/504 [==============================] - 0s 611us/step - loss: 28.7915\n",
            "Epoch 7/50\n",
            "504/504 [==============================] - 0s 647us/step - loss: 27.3068\n",
            "Epoch 8/50\n",
            "504/504 [==============================] - 0s 647us/step - loss: 25.9609\n",
            "Epoch 9/50\n",
            "504/504 [==============================] - 0s 594us/step - loss: 24.7620\n",
            "Epoch 10/50\n",
            "504/504 [==============================] - 0s 609us/step - loss: 23.6988\n",
            "Epoch 11/50\n",
            "504/504 [==============================] - 0s 618us/step - loss: 22.7363\n",
            "Epoch 12/50\n",
            "504/504 [==============================] - 0s 583us/step - loss: 21.8951\n",
            "Epoch 13/50\n",
            "504/504 [==============================] - 0s 596us/step - loss: 21.1325\n",
            "Epoch 14/50\n",
            "504/504 [==============================] - 0s 570us/step - loss: 20.4383\n",
            "Epoch 15/50\n",
            "504/504 [==============================] - 0s 585us/step - loss: 19.8088\n",
            "Epoch 16/50\n",
            "504/504 [==============================] - 0s 597us/step - loss: 19.2211\n",
            "Epoch 17/50\n",
            "504/504 [==============================] - 0s 587us/step - loss: 18.6557\n",
            "Epoch 18/50\n",
            "504/504 [==============================] - 0s 614us/step - loss: 18.1057\n",
            "Epoch 19/50\n",
            "504/504 [==============================] - 0s 601us/step - loss: 17.5637\n",
            "Epoch 20/50\n",
            "504/504 [==============================] - 0s 607us/step - loss: 17.0293\n",
            "Epoch 21/50\n",
            "504/504 [==============================] - 0s 607us/step - loss: 16.5037\n",
            "Epoch 22/50\n",
            "504/504 [==============================] - 0s 592us/step - loss: 15.9814\n",
            "Epoch 23/50\n",
            "504/504 [==============================] - 0s 601us/step - loss: 15.4930\n",
            "Epoch 24/50\n",
            "504/504 [==============================] - 0s 659us/step - loss: 15.0328\n",
            "Epoch 25/50\n",
            "504/504 [==============================] - 0s 574us/step - loss: 14.6190\n",
            "Epoch 26/50\n",
            "504/504 [==============================] - 0s 576us/step - loss: 14.2409\n",
            "Epoch 27/50\n",
            "504/504 [==============================] - 0s 583us/step - loss: 13.8708\n",
            "Epoch 28/50\n",
            "504/504 [==============================] - 0s 574us/step - loss: 13.5124\n",
            "Epoch 29/50\n",
            "504/504 [==============================] - 0s 579us/step - loss: 13.1709\n",
            "Epoch 30/50\n",
            "504/504 [==============================] - 0s 581us/step - loss: 12.8471\n",
            "Epoch 31/50\n",
            "504/504 [==============================] - 0s 577us/step - loss: 12.5184\n",
            "Epoch 32/50\n",
            "504/504 [==============================] - 0s 581us/step - loss: 12.1849\n",
            "Epoch 33/50\n",
            "504/504 [==============================] - 0s 572us/step - loss: 11.8485\n",
            "Epoch 34/50\n",
            "504/504 [==============================] - 0s 583us/step - loss: 11.5103\n",
            "Epoch 35/50\n",
            "504/504 [==============================] - 0s 586us/step - loss: 11.1885\n",
            "Epoch 36/50\n",
            "504/504 [==============================] - 0s 574us/step - loss: 10.8787\n",
            "Epoch 37/50\n",
            "504/504 [==============================] - 0s 580us/step - loss: 10.5829\n",
            "Epoch 38/50\n",
            "504/504 [==============================] - 0s 591us/step - loss: 10.3073\n",
            "Epoch 39/50\n",
            "504/504 [==============================] - 0s 572us/step - loss: 10.0514\n",
            "Epoch 40/50\n",
            "504/504 [==============================] - 0s 611us/step - loss: 9.8194\n",
            "Epoch 41/50\n",
            "504/504 [==============================] - 0s 593us/step - loss: 9.6098\n",
            "Epoch 42/50\n",
            "504/504 [==============================] - 0s 614us/step - loss: 9.4058\n",
            "Epoch 43/50\n",
            "504/504 [==============================] - 0s 600us/step - loss: 9.2199\n",
            "Epoch 44/50\n",
            "504/504 [==============================] - 0s 602us/step - loss: 9.0266\n",
            "Epoch 45/50\n",
            "504/504 [==============================] - 0s 583us/step - loss: 8.8552\n",
            "Epoch 46/50\n",
            "504/504 [==============================] - 0s 587us/step - loss: 8.6873\n",
            "Epoch 47/50\n",
            "504/504 [==============================] - 0s 591us/step - loss: 8.5269\n",
            "Epoch 48/50\n",
            "504/504 [==============================] - 0s 598us/step - loss: 8.3835\n",
            "Epoch 49/50\n",
            "504/504 [==============================] - 0s 603us/step - loss: 8.2516\n",
            "Epoch 50/50\n",
            "504/504 [==============================] - 0s 611us/step - loss: 8.1201\n",
            "22/22 [==============================] - 2s 90ms/step\n",
            "22/22 [==============================] - 0s 906us/step\n",
            "22/22 [==============================] - 0s 904us/step\n",
            "22/22 [==============================] - 0s 860us/step\n",
            "22/22 [==============================] - 0s 883us/step\n",
            "22/22 [==============================] - 0s 885us/step\n",
            "22/22 [==============================] - 0s 824us/step\n",
            "21/21 [==============================] - 0s 869us/step\n",
            "21/21 [==============================] - 0s 919us/step\n",
            "21/21 [==============================] - 0s 808us/step\n",
            "51/51 [==============================] - 0s 551us/step\n",
            "51/51 [==============================] - 0s 569us/step\n",
            "51/51 [==============================] - 0s 679us/step\n",
            "51/51 [==============================] - 0s 594us/step\n",
            "50/50 [==============================] - 0s 585us/step\n",
            "50/50 [==============================] - 0s 552us/step\n",
            "50/50 [==============================] - 0s 610us/step\n",
            "50/50 [==============================] - 0s 543us/step\n",
            "50/50 [==============================] - 0s 549us/step\n",
            "50/50 [==============================] - 0s 574us/step\n",
            "r 1 19.930686712265015 2.5004236698150635\n",
            "Epoch 1/50\n",
            "504/504 [==============================] - 5s 10ms/step - loss: 35.4605\n",
            "Epoch 2/50\n",
            "504/504 [==============================] - 0s 579us/step - loss: 34.5736\n",
            "Epoch 3/50\n",
            "504/504 [==============================] - 0s 601us/step - loss: 33.4572\n",
            "Epoch 4/50\n",
            "504/504 [==============================] - 0s 605us/step - loss: 31.8720\n",
            "Epoch 5/50\n",
            "504/504 [==============================] - 0s 624us/step - loss: 29.7853\n",
            "Epoch 6/50\n",
            "504/504 [==============================] - 0s 608us/step - loss: 27.2046\n",
            "Epoch 7/50\n",
            "504/504 [==============================] - 0s 638us/step - loss: 24.2911\n",
            "Epoch 8/50\n",
            "504/504 [==============================] - 0s 603us/step - loss: 21.3214\n",
            "Epoch 9/50\n",
            "504/504 [==============================] - 0s 589us/step - loss: 18.4103\n",
            "Epoch 10/50\n",
            "504/504 [==============================] - 0s 609us/step - loss: 15.7846\n",
            "Epoch 11/50\n",
            "504/504 [==============================] - 0s 632us/step - loss: 13.4781\n",
            "Epoch 12/50\n",
            "504/504 [==============================] - 0s 599us/step - loss: 11.7792\n",
            "Epoch 13/50\n",
            "504/504 [==============================] - 0s 622us/step - loss: 10.5153\n",
            "Epoch 14/50\n",
            "504/504 [==============================] - 0s 598us/step - loss: 9.6440\n",
            "Epoch 15/50\n",
            "504/504 [==============================] - 0s 594us/step - loss: 9.1075\n",
            "Epoch 16/50\n",
            "504/504 [==============================] - 0s 608us/step - loss: 8.7030\n",
            "Epoch 17/50\n",
            "504/504 [==============================] - 0s 623us/step - loss: 8.3983\n",
            "Epoch 18/50\n",
            "504/504 [==============================] - 0s 571us/step - loss: 8.1391\n",
            "Epoch 19/50\n",
            "504/504 [==============================] - 0s 568us/step - loss: 7.9351\n",
            "Epoch 20/50\n",
            "504/504 [==============================] - 0s 581us/step - loss: 7.7869\n",
            "Epoch 21/50\n",
            "504/504 [==============================] - 0s 557us/step - loss: 7.6707\n",
            "Epoch 22/50\n",
            "504/504 [==============================] - 0s 614us/step - loss: 7.5645\n",
            "Epoch 23/50\n",
            "504/504 [==============================] - 0s 651us/step - loss: 7.4728\n",
            "Epoch 24/50\n",
            "504/504 [==============================] - 0s 612us/step - loss: 7.3814\n",
            "Epoch 25/50\n",
            "504/504 [==============================] - 0s 614us/step - loss: 7.2983\n",
            "Epoch 26/50\n",
            "504/504 [==============================] - 0s 633us/step - loss: 7.2090\n",
            "Epoch 27/50\n",
            "504/504 [==============================] - 0s 592us/step - loss: 7.1256\n",
            "Epoch 28/50\n",
            "504/504 [==============================] - 0s 637us/step - loss: 7.0448\n",
            "Epoch 29/50\n",
            "504/504 [==============================] - 0s 606us/step - loss: 6.9517\n",
            "Epoch 30/50\n",
            "504/504 [==============================] - 0s 644us/step - loss: 6.8594\n",
            "Epoch 31/50\n",
            "504/504 [==============================] - 0s 594us/step - loss: 6.7725\n",
            "Epoch 32/50\n",
            "504/504 [==============================] - 0s 574us/step - loss: 6.6778\n",
            "Epoch 33/50\n",
            "504/504 [==============================] - 0s 593us/step - loss: 6.5948\n",
            "Epoch 34/50\n",
            "504/504 [==============================] - 0s 595us/step - loss: 6.4972\n",
            "Epoch 35/50\n",
            "504/504 [==============================] - 0s 602us/step - loss: 6.4031\n",
            "Epoch 36/50\n",
            "504/504 [==============================] - 0s 607us/step - loss: 6.3090\n",
            "Epoch 37/50\n",
            "504/504 [==============================] - 0s 590us/step - loss: 6.2261\n",
            "Epoch 38/50\n",
            "504/504 [==============================] - 0s 587us/step - loss: 6.1501\n",
            "Epoch 39/50\n",
            "504/504 [==============================] - 0s 572us/step - loss: 6.0642\n",
            "Epoch 40/50\n",
            "504/504 [==============================] - 0s 600us/step - loss: 5.9955\n",
            "Epoch 41/50\n",
            "504/504 [==============================] - 0s 607us/step - loss: 5.9348\n",
            "Epoch 42/50\n",
            "504/504 [==============================] - 0s 592us/step - loss: 5.8673\n",
            "Epoch 43/50\n",
            "504/504 [==============================] - 0s 672us/step - loss: 5.8150\n",
            "Epoch 44/50\n",
            "504/504 [==============================] - 0s 596us/step - loss: 5.7597\n",
            "Epoch 45/50\n",
            "504/504 [==============================] - 0s 636us/step - loss: 5.7064\n",
            "Epoch 46/50\n",
            "504/504 [==============================] - 0s 614us/step - loss: 5.6492\n",
            "Epoch 47/50\n",
            "504/504 [==============================] - 0s 587us/step - loss: 5.6026\n",
            "Epoch 48/50\n",
            "504/504 [==============================] - 0s 587us/step - loss: 5.5778\n",
            "Epoch 49/50\n",
            "504/504 [==============================] - 0s 600us/step - loss: 5.5241\n",
            "Epoch 50/50\n",
            "504/504 [==============================] - 0s 611us/step - loss: 5.4937\n",
            "22/22 [==============================] - 2s 91ms/step\n",
            "22/22 [==============================] - 0s 854us/step\n",
            "22/22 [==============================] - 0s 897us/step\n",
            "22/22 [==============================] - 0s 769us/step\n",
            "22/22 [==============================] - 0s 821us/step\n",
            "22/22 [==============================] - 0s 788us/step\n",
            "22/22 [==============================] - 0s 891us/step\n",
            "21/21 [==============================] - 0s 827us/step\n",
            "21/21 [==============================] - 0s 996us/step\n",
            "21/21 [==============================] - 0s 995us/step\n",
            "51/51 [==============================] - 0s 623us/step\n",
            "51/51 [==============================] - 0s 615us/step\n",
            "51/51 [==============================] - 0s 615us/step\n",
            "51/51 [==============================] - 0s 670us/step\n",
            "50/50 [==============================] - 0s 621us/step\n",
            "50/50 [==============================] - 0s 626us/step\n",
            "50/50 [==============================] - 0s 593us/step\n",
            "50/50 [==============================] - 0s 567us/step\n",
            "50/50 [==============================] - 0s 598us/step\n",
            "50/50 [==============================] - 0s 608us/step\n",
            "r 2 20.157033681869507 2.54274845123291\n",
            "r 3 4.896723031997681 0.044536590576171875\n",
            "r 4 1.8742997646331787 0.01737499237060547\n",
            "r 5 2.3118185997009277 0.050931692123413086\n",
            "r 6 20.127264499664307 0.00890803337097168\n",
            "r 7 9.163062334060669 0.008672475814819336\n",
            "r 8 11.60996150970459 0.01587080955505371\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_aRO0poTqWTg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ":\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "snIgGTotMC55",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ch9WkJystnKr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SA7CzJaWtfKq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "a9fbb8e9-d374-4dbe-9ab3-486370fbcf73"
      },
      "cell_type": "code",
      "source": [
        "test_scores = numpy.array([r[1][0] for r in results])\n",
        "train_scores = numpy.array([r[1][1] for r in results])\n",
        "\n",
        "def selected_params(r):\n",
        "    details = r[1][2]\n",
        "    if 'mean_test_score' in details.keys():\n",
        "      df = pandas.DataFrame(details)\n",
        "      s = df.sort_values('rank_test_score', ascending=True)\n",
        "      return s.params.iloc[0]\n",
        "    else:\n",
        "      return None\n",
        "\n",
        "df = pandas.DataFrame({\n",
        "    'test_mean': test_scores.mean(axis=1),\n",
        "    'test_std': test_scores.std(axis=1),\n",
        "    'train_mean': train_scores.mean(axis=1),\n",
        "    'train_std': train_scores.std(axis=1),\n",
        "    'model': [ r[0] for r in results ],\n",
        "    'train_time': [ r[1][3] for r in results ],\n",
        "    'predict_time': [ r[1][4] for r in results ],\n",
        "    'params': [ selected_params(r) for r in results ],\n",
        "})\n",
        "df.sort_values(by='test_mean', ascending=True).head(10)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>params</th>\n",
              "      <th>predict_time</th>\n",
              "      <th>test_mean</th>\n",
              "      <th>test_std</th>\n",
              "      <th>train_mean</th>\n",
              "      <th>train_std</th>\n",
              "      <th>train_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>{'min_samples_leaf': 1}</td>\n",
              "      <td>0.050932</td>\n",
              "      <td>4.137398</td>\n",
              "      <td>0.474259</td>\n",
              "      <td>1.595700</td>\n",
              "      <td>0.301961</td>\n",
              "      <td>2.311819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SVM rbf</td>\n",
              "      <td>{'C': 104.81131341546852}</td>\n",
              "      <td>0.015871</td>\n",
              "      <td>4.510368</td>\n",
              "      <td>0.960680</td>\n",
              "      <td>2.789694</td>\n",
              "      <td>0.633476</td>\n",
              "      <td>11.609962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Poly3-Ridge</td>\n",
              "      <td>{'ridge__alpha': 1.151395399326447}</td>\n",
              "      <td>0.044537</td>\n",
              "      <td>5.460879</td>\n",
              "      <td>1.436678</td>\n",
              "      <td>3.288003</td>\n",
              "      <td>0.450783</td>\n",
              "      <td>4.896723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MLP 16-16 Relu</td>\n",
              "      <td>None</td>\n",
              "      <td>2.542748</td>\n",
              "      <td>6.097163</td>\n",
              "      <td>1.564195</td>\n",
              "      <td>5.447361</td>\n",
              "      <td>0.850862</td>\n",
              "      <td>20.157034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>SVM poly3</td>\n",
              "      <td>{'C': 1000.0}</td>\n",
              "      <td>0.008908</td>\n",
              "      <td>6.167713</td>\n",
              "      <td>1.777015</td>\n",
              "      <td>4.122659</td>\n",
              "      <td>0.830140</td>\n",
              "      <td>20.127264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Poly2-Ridge</td>\n",
              "      <td>{'ridge__alpha': 0.28117686979742307}</td>\n",
              "      <td>0.017375</td>\n",
              "      <td>6.655942</td>\n",
              "      <td>1.185258</td>\n",
              "      <td>5.234722</td>\n",
              "      <td>0.944606</td>\n",
              "      <td>1.874300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SVM poly2</td>\n",
              "      <td>{'C': 104.81131341546852}</td>\n",
              "      <td>0.008672</td>\n",
              "      <td>7.370464</td>\n",
              "      <td>1.420235</td>\n",
              "      <td>5.916535</td>\n",
              "      <td>0.888379</td>\n",
              "      <td>9.163062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MLP 8-8 tanh</td>\n",
              "      <td>None</td>\n",
              "      <td>2.500424</td>\n",
              "      <td>7.808446</td>\n",
              "      <td>1.039799</td>\n",
              "      <td>8.048932</td>\n",
              "      <td>0.853400</td>\n",
              "      <td>19.930687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MLP 8-8 ReLu</td>\n",
              "      <td>None</td>\n",
              "      <td>2.462641</td>\n",
              "      <td>7.882853</td>\n",
              "      <td>2.286932</td>\n",
              "      <td>6.422631</td>\n",
              "      <td>1.226349</td>\n",
              "      <td>20.256497</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            model                                 params  predict_time  \\\n",
              "5    RandomForest                {'min_samples_leaf': 1}      0.050932   \n",
              "8         SVM rbf              {'C': 104.81131341546852}      0.015871   \n",
              "3     Poly3-Ridge    {'ridge__alpha': 1.151395399326447}      0.044537   \n",
              "2  MLP 16-16 Relu                                   None      2.542748   \n",
              "6       SVM poly3                          {'C': 1000.0}      0.008908   \n",
              "4     Poly2-Ridge  {'ridge__alpha': 0.28117686979742307}      0.017375   \n",
              "7       SVM poly2              {'C': 104.81131341546852}      0.008672   \n",
              "1    MLP 8-8 tanh                                   None      2.500424   \n",
              "0    MLP 8-8 ReLu                                   None      2.462641   \n",
              "\n",
              "   test_mean  test_std  train_mean  train_std  train_time  \n",
              "5   4.137398  0.474259    1.595700   0.301961    2.311819  \n",
              "8   4.510368  0.960680    2.789694   0.633476   11.609962  \n",
              "3   5.460879  1.436678    3.288003   0.450783    4.896723  \n",
              "2   6.097163  1.564195    5.447361   0.850862   20.157034  \n",
              "6   6.167713  1.777015    4.122659   0.830140   20.127264  \n",
              "4   6.655942  1.185258    5.234722   0.944606    1.874300  \n",
              "7   7.370464  1.420235    5.916535   0.888379    9.163062  \n",
              "1   7.808446  1.039799    8.048932   0.853400   19.930687  \n",
              "0   7.882853  2.286932    6.422631   1.226349   20.256497  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "metadata": {
        "id": "RpnRhJI50TMy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}