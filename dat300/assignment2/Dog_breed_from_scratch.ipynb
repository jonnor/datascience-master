{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dog breed from scratch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "1zYpvPzwz3m_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Classifying dog species with Convolutional Neural Networks\n",
        "DAT300, group CA2-10. Jon Nordby and Espen Sønneland.\n",
        "\n",
        "\n",
        "## Kaggle setup\n",
        "Downloads data from https://www.kaggle.com/c/dat300-2018-dogs"
      ]
    },
    {
      "metadata": {
        "id": "paWTz67gLwxY",
        "colab_type": "code",
        "outputId": "2216055c-56f5-4951-89af-27d6a9fddbd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle && echo Kaggle installed"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kaggle installed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x240wcGZL1OH",
        "colab_type": "code",
        "outputId": "2d10417d-13b8-4f64-c58c-776775fa6092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import shutil, os, os.path\n",
        "drive.mount('/content/drive')\n",
        "if not os.path.exists('/root/.kaggle'):\n",
        "  os.makedirs('/root/.kaggle/')\n",
        "shutil.copyfile('/content/drive/My Drive/kaggle.json', '/root/.kaggle/kaggle.json')\n",
        "'Kaggle API key installed'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Kaggle API key installed'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "xxZKXQt8g60X",
        "colab_type": "code",
        "outputId": "8c0d954d-9ae6-4c8f-9028-88966eb0bd4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c dat300-2018-dogs -p data/\n",
        "!unzip -n -q 'data/*.zip' -d data/\n",
        "!ls data/train/*.jpg | wc -l\n",
        "!ls data/test/*.jpg | wc -l"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by otherusers on this system! To fix this, you can run'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading sampleSubmission.csv.zip to data\n",
            "  0% 0.00/109k [00:00<?, ?B/s]\n",
            "100% 109k/109k [00:00<00:00, 47.4MB/s]\n",
            "Downloading labels.csv to data\n",
            "  0% 0.00/202k [00:00<?, ?B/s]\n",
            "100% 202k/202k [00:00<00:00, 74.8MB/s]\n",
            "Downloading test.zip to data\n",
            " 97% 361M/371M [00:05<00:00, 69.7MB/s]\n",
            "100% 371M/371M [00:05<00:00, 71.0MB/s]\n",
            "Downloading train.zip to data\n",
            " 94% 346M/369M [00:05<00:00, 54.6MB/s]\n",
            "100% 369M/369M [00:06<00:00, 64.3MB/s]\n",
            "\n",
            "3 archives were successfully processed.\n",
            "10290\n",
            "10290\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yjXtVMqphifK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "70daefaa-68d9-427a-c8ad-ebba2ccc9c5f"
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os\n",
        "import re\n",
        "\n",
        "import pandas\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn\n",
        "\n",
        "import sklearn.preprocessing\n",
        "import sklearn.model_selection\n",
        "import sklearn.pipeline\n",
        "\n",
        "import sklearn.linear_model\n",
        "import sklearn.ensemble\n",
        "import sklearn.svm\n",
        "\n",
        "import keras\n",
        "import keras.wrappers.scikit_learn"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "rnDG8pJghzpY",
        "colab_type": "code",
        "outputId": "99527d8f-21ab-43ec-af6a-a3985cba0200",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        }
      },
      "cell_type": "code",
      "source": [
        "labels = pandas.read_csv('data/labels.csv', index_col='id')\n",
        "\n",
        "print(labels.shape)\n",
        "labels.head(3)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10290, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>breed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>soft-coated_wheaten_terrier</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tibetan_terrier</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Lhasa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          breed\n",
              "id                             \n",
              "0   soft-coated_wheaten_terrier\n",
              "1               Tibetan_terrier\n",
              "2                         Lhasa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "QCtj7AMgkZ_Z",
        "colab_type": "code",
        "outputId": "77b0502d-059d-4a98-9524-f6c2faa6fc39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "print('number of breeds', len(labels.breed.unique()))\n",
        "print('images per breed (average)', len(labels)/len(labels.breed.unique()))\n",
        " "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of breeds 120\n",
            "images per breed (average) 85.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zv0La7rOItbT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Under 100 images per class is considered **very few** for training deep learning models."
      ]
    },
    {
      "metadata": {
        "id": "EWxuw4-EXJXS",
        "colab_type": "code",
        "outputId": "01788c35-0664-448a-a946-61342e19daad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "cell_type": "code",
      "source": [
        "# Create a pandas.DataFrame with the samples (id, filename)\n",
        "def files_dataframe(directory):\n",
        "  import glob\n",
        "  import re\n",
        "  files = {}\n",
        "  for filename in glob.iglob(directory+'/*.jpg'):\n",
        "    m = re.findall('dog(\\d+).jpg', filename)\n",
        "    file_id = int(m[0])\n",
        "    files[file_id] = os.path.basename(filename)\n",
        "  filenames = list(files.values())\n",
        "\n",
        "  ids = list(files.keys())\n",
        "  df = pandas.DataFrame({\n",
        "      'filename': filenames,\n",
        "      'filepath': [ os.path.join(directory, f) for f in filenames ],\n",
        "  }, index=ids)\n",
        "  df.sort_index(inplace=True) # make sure ordered by id\n",
        "  assert df.filename.values[0] == 'dog0.jpg'\n",
        "  return df\n",
        "\n",
        "train_files = files_dataframe('data/train')\n",
        "_ = files_dataframe('data/test') # just ensure it runs without error\n",
        "train_data = train_files.join(labels)\n",
        "train_data.head(3)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>filepath</th>\n",
              "      <th>breed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dog0.jpg</td>\n",
              "      <td>data/train/dog0.jpg</td>\n",
              "      <td>soft-coated_wheaten_terrier</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dog1.jpg</td>\n",
              "      <td>data/train/dog1.jpg</td>\n",
              "      <td>Tibetan_terrier</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dog2.jpg</td>\n",
              "      <td>data/train/dog2.jpg</td>\n",
              "      <td>Lhasa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   filename             filepath                        breed\n",
              "0  dog0.jpg  data/train/dog0.jpg  soft-coated_wheaten_terrier\n",
              "1  dog1.jpg  data/train/dog1.jpg              Tibetan_terrier\n",
              "2  dog2.jpg  data/train/dog2.jpg                        Lhasa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "_x8rcdyI00ej",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training CNN from scratch\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "95TZAqyApRA7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_model(image_size=(150, 150), n_classes=120, complexity=2, dropout=0.3):\n",
        "  from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "  from keras.layers import Dropout, Activation, Dense, Flatten\n",
        "  from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "  model = keras.Sequential()\n",
        "\n",
        "  in_shape = (image_size[0], image_size[1], 3)\n",
        "  model.add(Conv2D(16, (3, 3), padding='same', use_bias=False, input_shape=in_shape))\n",
        "  model.add(BatchNormalization(axis=3, scale=False))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'))\n",
        "  model.add(Dropout(dropout))\n",
        "\n",
        "  if complexity > 1:\n",
        "    model.add(Conv2D(32, (3, 3), padding='same', use_bias=False))\n",
        "    model.add(BatchNormalization(axis=3, scale=False))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'))\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "  if complexity > 2:\n",
        "    model.add(Conv2D(64, (3, 3), padding='same', use_bias=False))\n",
        "    model.add(BatchNormalization(axis=3, scale=False))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'))\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "  if complexity > 3:\n",
        "    model.add(Conv2D(128, (3, 3), padding='same', use_bias=False))\n",
        "    model.add(BatchNormalization(axis=3, scale=False))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  model.add(Dense(n_classes, activation='softmax'))\n",
        "  \n",
        "  model.compile(optimizer='rmsprop',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vaWS4-Fak5dl",
        "colab_type": "code",
        "outputId": "766baa4f-071d-4327-96e8-32005ed9dc35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 940
        }
      },
      "cell_type": "code",
      "source": [
        "def train_model(train_dir, complexity=3):\n",
        "  image_size = (120, 120)\n",
        "  epochs = 20\n",
        "  batch_size = 32\n",
        "  labels = pandas.read_csv('data/labels.csv', index_col='id')\n",
        "  labeled_data = files_dataframe(train_dir).join(labels)\n",
        "  \n",
        "  # Setup model\n",
        "  model = build_model(image_size=image_size,complexity=complexity, dropout=0.2)\n",
        "  model.summary()\n",
        "  \n",
        "  outdir = '/content/drive/My Drive/dat300-dogs'\n",
        "  weigthspath = os.path.join(outdir, 'scratch.c{}.best.hdf5'.format(complexity))\n",
        "  from keras.callbacks import ModelCheckpoint\n",
        "  checkpointer = ModelCheckpoint(filepath=weigthspath, \n",
        "                                 verbose=1, save_best_only=True)\n",
        "  \n",
        "\n",
        "  # Setup data augmentation\n",
        "  from keras.preprocessing.image import ImageDataGenerator\n",
        "  train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    rotation_range=30,\n",
        "    vertical_flip=False,\n",
        "    horizontal_flip=True)\n",
        "  \n",
        "  test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "  # Split training and validation data\n",
        "  train_data = labeled_data.iloc[0:7000]\n",
        "  val_data = labeled_data.iloc[7000:]\n",
        "  # flow_from_dataframe raises Exception if we dont start from 0...\n",
        "  val_data['i'] = range(0, len(val_data))\n",
        "  val_data.set_index('i', inplace=True)\n",
        "  \n",
        "  # Train model\n",
        "  train_generator = train_datagen.flow_from_dataframe(\n",
        "          train_data,\n",
        "          train_dir,\n",
        "          y_col='breed',\n",
        "          target_size=image_size,\n",
        "          batch_size=batch_size,\n",
        "          class_mode='categorical')\n",
        "\n",
        "  validation_generator = test_datagen.flow_from_dataframe(\n",
        "          val_data,\n",
        "          train_dir,\n",
        "          y_col='breed',\n",
        "          target_size=image_size,\n",
        "          batch_size=batch_size,\n",
        "          class_mode='categorical')\n",
        "  \n",
        "  model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=4000//batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=2000//batch_size,\n",
        "        callbacks=[checkpointer], verbose=1)\n",
        "\n",
        "\n",
        "fromscratch = train_model('data/train')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_73 (Conv2D)           (None, 120, 120, 16)      432       \n",
            "_________________________________________________________________\n",
            "batch_normalization_72 (Batc (None, 120, 120, 16)      48        \n",
            "_________________________________________________________________\n",
            "activation_72 (Activation)   (None, 120, 120, 16)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_63 (MaxPooling (None, 30, 30, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_72 (Dropout)         (None, 30, 30, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_74 (Conv2D)           (None, 30, 30, 32)        4608      \n",
            "_________________________________________________________________\n",
            "batch_normalization_73 (Batc (None, 30, 30, 32)        96        \n",
            "_________________________________________________________________\n",
            "activation_73 (Activation)   (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_64 (MaxPooling (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_73 (Dropout)         (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_75 (Conv2D)           (None, 8, 8, 64)          18432     \n",
            "_________________________________________________________________\n",
            "batch_normalization_74 (Batc (None, 8, 8, 64)          192       \n",
            "_________________________________________________________________\n",
            "activation_74 (Activation)   (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_65 (MaxPooling (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_74 (Dropout)         (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_18 (Flatten)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 120)               61560     \n",
            "=================================================================\n",
            "Total params: 216,952\n",
            "Trainable params: 216,728\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 7000 images belonging to 120 classes.\n",
            "Found 3290 images belonging to 120 classes.\n",
            "Epoch 1/20\n",
            " 38/125 [========>.....................] - ETA: 27s - loss: 5.1380 - acc: 0.0066 - top_k_categorical_accuracy: 0.0436"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zddurn4NWMqq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tried many combinations of `complexity` (1-4), `dropout` (0.2-0.5), and `batch_size` (20-200) and image_sizes (120,224) - but unable to make the network train well. Usually ends up overfitting within 3-5 epochs, at losses of `~4.80` - which is practically the equal probability performance.\n",
        "\n",
        "This is suprising, since the architecture of this CNN was able to get 11% accuracy on a 133 class dog breed problem, without use of data augmentation. [machinememos.com: dog-breed-image-classifcation](http://machinememos.com/python/keras/artificial%20intelligence/machine%20learning/transfer%20learning/dog%20breed/neural%20networks/convolutional%20neural%20network/tensorflow/image%20classification/imagenet/2017/07/11/dog-breed-image-classification.html)"
      ]
    }
  ]
}