{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT300 CA1: Selecting features for nuclear forensics \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "\n",
    "import pandas\n",
    "import numpy\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import sklearn.ensemble\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "import sklearn.feature_selection\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a combined DataFrame, and a dictionary of {featuretype: columns}\n",
    "def load_data(filename):\n",
    "    def load_sheet(name):\n",
    "        df = file.parse(name)\n",
    "        if 'Index' in df.columns:\n",
    "            # we index based on row number\n",
    "            del df['Index']\n",
    "        else:\n",
    "            # remove duplicated labels\n",
    "            del df['Labels']\n",
    "        return df\n",
    "    \n",
    "    file = pandas.ExcelFile(filename)\n",
    "    dfs = { sheet: load_sheet(sheet) for sheet in file.sheet_names}\n",
    "    \n",
    "    # AMT is missing names for columns\n",
    "    combine = [dfs[k] for k in dfs.keys() if k not in ('AMT')]\n",
    "    \n",
    "    combined = dfs['AMT'].copy().add_suffix('-AMT')\n",
    "    combined = combined.join(combine, lsuffix='', rsuffix='')\n",
    "    \n",
    "    feature_categories = {}\n",
    "    for category, df in dfs.items():\n",
    "        columns = df.columns\n",
    "        feature_categories[category] = columns\n",
    "    \n",
    "    return combined, feature_categories\n",
    "\n",
    "fulldata, categories = load_data('DAT300 - CA 1_NEW.xlsx')\n",
    "assert fulldata.shape[0] == 120, fulldata.shape\n",
    "assert numpy.count_nonzero(fulldata.Labels.isnull()) == 0, numpy.count_nonzero(fulldata.Labels.isnull())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Target', 'AMT', 'WT_originals', 'WT-LLL', 'WT-LLH', 'WT_LHL', 'WT_LHH', 'LBP'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-AMT</th>\n",
       "      <th>2-AMT</th>\n",
       "      <th>3-AMT</th>\n",
       "      <th>4-AMT</th>\n",
       "      <th>5-AMT</th>\n",
       "      <th>6-AMT</th>\n",
       "      <th>7-AMT</th>\n",
       "      <th>8-AMT</th>\n",
       "      <th>9-AMT</th>\n",
       "      <th>10-AMT</th>\n",
       "      <th>...</th>\n",
       "      <th>lbp_24_(24,3)</th>\n",
       "      <th>lbp_25_(24,3)</th>\n",
       "      <th>lbp_2_(24,3)</th>\n",
       "      <th>lbp_3_(24,3)</th>\n",
       "      <th>lbp_4_(24,3)</th>\n",
       "      <th>lbp_5_(24,3)</th>\n",
       "      <th>lbp_6_(24,3)</th>\n",
       "      <th>lbp_7_(24,3)</th>\n",
       "      <th>lbp_8_(24,3)</th>\n",
       "      <th>lbp_9_(24,3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.55144</td>\n",
       "      <td>1.51980</td>\n",
       "      <td>1.45847</td>\n",
       "      <td>1.43940</td>\n",
       "      <td>1.43263</td>\n",
       "      <td>1.44893</td>\n",
       "      <td>1.50741</td>\n",
       "      <td>1.54977</td>\n",
       "      <td>1.59866</td>\n",
       "      <td>1.63075</td>\n",
       "      <td>...</td>\n",
       "      <td>53695</td>\n",
       "      <td>468638</td>\n",
       "      <td>17261</td>\n",
       "      <td>15439</td>\n",
       "      <td>18953</td>\n",
       "      <td>22857</td>\n",
       "      <td>24262</td>\n",
       "      <td>26894</td>\n",
       "      <td>27454</td>\n",
       "      <td>29276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51458</td>\n",
       "      <td>1.47539</td>\n",
       "      <td>1.45449</td>\n",
       "      <td>1.46195</td>\n",
       "      <td>1.44090</td>\n",
       "      <td>1.47846</td>\n",
       "      <td>1.51607</td>\n",
       "      <td>1.53459</td>\n",
       "      <td>1.51287</td>\n",
       "      <td>1.54192</td>\n",
       "      <td>...</td>\n",
       "      <td>53047</td>\n",
       "      <td>462418</td>\n",
       "      <td>16941</td>\n",
       "      <td>15294</td>\n",
       "      <td>18823</td>\n",
       "      <td>22369</td>\n",
       "      <td>24826</td>\n",
       "      <td>27250</td>\n",
       "      <td>28437</td>\n",
       "      <td>30374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.50565</td>\n",
       "      <td>1.46602</td>\n",
       "      <td>1.44400</td>\n",
       "      <td>1.45143</td>\n",
       "      <td>1.42508</td>\n",
       "      <td>1.41574</td>\n",
       "      <td>1.44243</td>\n",
       "      <td>1.47648</td>\n",
       "      <td>1.44198</td>\n",
       "      <td>1.45998</td>\n",
       "      <td>...</td>\n",
       "      <td>53917</td>\n",
       "      <td>469225</td>\n",
       "      <td>17328</td>\n",
       "      <td>15441</td>\n",
       "      <td>19056</td>\n",
       "      <td>22997</td>\n",
       "      <td>24702</td>\n",
       "      <td>26641</td>\n",
       "      <td>27585</td>\n",
       "      <td>29121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.53664</td>\n",
       "      <td>1.50323</td>\n",
       "      <td>1.46508</td>\n",
       "      <td>1.42571</td>\n",
       "      <td>1.43470</td>\n",
       "      <td>1.42078</td>\n",
       "      <td>1.44322</td>\n",
       "      <td>1.45240</td>\n",
       "      <td>1.46457</td>\n",
       "      <td>1.51837</td>\n",
       "      <td>...</td>\n",
       "      <td>53643</td>\n",
       "      <td>465916</td>\n",
       "      <td>16694</td>\n",
       "      <td>15318</td>\n",
       "      <td>18830</td>\n",
       "      <td>22634</td>\n",
       "      <td>24608</td>\n",
       "      <td>26706</td>\n",
       "      <td>27805</td>\n",
       "      <td>29507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.52808</td>\n",
       "      <td>1.47522</td>\n",
       "      <td>1.45618</td>\n",
       "      <td>1.37537</td>\n",
       "      <td>1.37561</td>\n",
       "      <td>1.39346</td>\n",
       "      <td>1.42378</td>\n",
       "      <td>1.46455</td>\n",
       "      <td>1.47553</td>\n",
       "      <td>1.46507</td>\n",
       "      <td>...</td>\n",
       "      <td>48987</td>\n",
       "      <td>456795</td>\n",
       "      <td>15882</td>\n",
       "      <td>14244</td>\n",
       "      <td>17120</td>\n",
       "      <td>20866</td>\n",
       "      <td>23471</td>\n",
       "      <td>26877</td>\n",
       "      <td>28607</td>\n",
       "      <td>31338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1426 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1-AMT    2-AMT    3-AMT    4-AMT    5-AMT    6-AMT    7-AMT    8-AMT  \\\n",
       "0  1.55144  1.51980  1.45847  1.43940  1.43263  1.44893  1.50741  1.54977   \n",
       "1  1.51458  1.47539  1.45449  1.46195  1.44090  1.47846  1.51607  1.53459   \n",
       "2  1.50565  1.46602  1.44400  1.45143  1.42508  1.41574  1.44243  1.47648   \n",
       "3  1.53664  1.50323  1.46508  1.42571  1.43470  1.42078  1.44322  1.45240   \n",
       "4  1.52808  1.47522  1.45618  1.37537  1.37561  1.39346  1.42378  1.46455   \n",
       "\n",
       "     9-AMT   10-AMT      ...       lbp_24_(24,3)  lbp_25_(24,3)  lbp_2_(24,3)  \\\n",
       "0  1.59866  1.63075      ...               53695         468638         17261   \n",
       "1  1.51287  1.54192      ...               53047         462418         16941   \n",
       "2  1.44198  1.45998      ...               53917         469225         17328   \n",
       "3  1.46457  1.51837      ...               53643         465916         16694   \n",
       "4  1.47553  1.46507      ...               48987         456795         15882   \n",
       "\n",
       "   lbp_3_(24,3)  lbp_4_(24,3)  lbp_5_(24,3)  lbp_6_(24,3)  lbp_7_(24,3)  \\\n",
       "0         15439         18953         22857         24262         26894   \n",
       "1         15294         18823         22369         24826         27250   \n",
       "2         15441         19056         22997         24702         26641   \n",
       "3         15318         18830         22634         24608         26706   \n",
       "4         14244         17120         20866         23471         26877   \n",
       "\n",
       "   lbp_8_(24,3)  lbp_9_(24,3)  \n",
       "0         27454         29276  \n",
       "1         28437         30374  \n",
       "2         27585         29121  \n",
       "3         27805         29507  \n",
       "4         28607         31338  \n",
       "\n",
       "[5 rows x 1426 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 1426)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_XY(data, feature_columns=None):\n",
    "    all_feature_columns = list(set(data.columns) - set(['Labels']))\n",
    "    \n",
    "    use = data[data.Labels.notna()]\n",
    "    X = use[all_feature_columns].astype(float)\n",
    "    if feature_columns is not None:\n",
    "        feature_columns = list(feature_columns)\n",
    "        X = X.iloc[:,feature_columns]\n",
    "    y = use.Labels\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN = ( sklearn.neighbors.KNeighborsClassifier(), {\n",
    "       'n_neighbors': [1,2,3,4],\n",
    "})\n",
    "RandomForest = ( sklearn.ensemble.RandomForestClassifier(), {\n",
    "    'n_estimators': [10, 30, 100],\n",
    "    'min_samples_leaf': [0.01, 0.1],\n",
    "})\n",
    "Logistic = ( sklearn.linear_model.LogisticRegression(multi_class='ovr', solver='liblinear'),  {\n",
    "    'C': [ 0.75, 0.5, 0.25 ],\n",
    "})\n",
    "\n",
    "# TODO: add GBT\n",
    "# MAYBE: add SVM polynomial\n",
    "\n",
    "models = [\n",
    "    kNN,\n",
    "    RandomForest,\n",
    "    Logistic,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_candidate(dataset, cand, gridcv=5, n_tests=100, seed=0, evalcv=3):\n",
    "    model, params, features = cand\n",
    "\n",
    "    # Reduce to subset of features\n",
    "    X, y = get_XY(dataset, features)\n",
    "    X = sklearn.preprocessing.RobustScaler().fit_transform(X)\n",
    "    \n",
    "    # Decide hyperparameters\n",
    "    gridsearch_start = time.time()\n",
    "    grid = sklearn.model_selection.GridSearchCV(model, params, cv=gridcv,\n",
    "                                                iid=False, refit=True, return_train_score=True)\n",
    "    grid.fit(X, y)\n",
    "    estimator = grid.best_estimator_\n",
    "    \n",
    "    gridsearch_time = time.time() - gridsearch_start\n",
    "    \n",
    "    # Evaluate on a range of test-train splits\n",
    "    numpy.random.seed(seed)\n",
    "    test_scores = numpy.array([])\n",
    "    train_scores = numpy.array([])\n",
    "\n",
    "    evaluate_start = time.time()\n",
    "    for rng in numpy.random.randint(0, 1000, size=n_tests):\n",
    "        X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.4, random_state=rng)\n",
    "\n",
    "        estimator.fit(X_train, Y_train)\n",
    "\n",
    "        # FIXME: calculate score across whole test/trainset\n",
    "        test = sklearn.model_selection.cross_val_score(estimator, X_test, Y_test, cv=evalcv)\n",
    "        train = sklearn.model_selection.cross_val_score(estimator, X_train, Y_train, cv=evalcv)\n",
    "        \n",
    "        test_scores = numpy.concatenate([test_scores, test]) \n",
    "        train_scores = numpy.concatenate([train_scores, train])\n",
    "    evaluate_time =  time.time() - evaluate_start\n",
    "    \n",
    "    return test_scores, train_scores, grid.cv_results_, gridsearch_time, evaluate_time\n",
    "\n",
    "def test_evaluate_candidate():\n",
    "    all_features = None\n",
    "    candidate = (sklearn.ensemble.RandomForestClassifier(n_estimators=10), {}, all_features)\n",
    "    r = evaluate_candidate(fulldata, candidate, n_tests=10)\n",
    "    assert len(r) == 5\n",
    "                       \n",
    "test_evaluate_candidate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "\n",
    "### Random selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_candidates(models, feature_lengths, n_random=5, max_features=1425):\n",
    "    candidates = []\n",
    "    for n_features in feature_lengths:\n",
    "        random_features = numpy.random.choice(range(max_features), size=(n_random, n_features), replace=False)\n",
    "        for features in random_features:\n",
    "            for (m,p) in models:\n",
    "                candidates.append(( m, p, features, 'random' ))\n",
    "\n",
    "    return candidates\n",
    "random_candidates(models, (1,), 5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate feature scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_score_rf(X, y, n_reps=30):\n",
    "    importances = numpy.ndarray((n_reps, X.shape[1]))\n",
    "    # RF tends to ignore redundant features, so average over many runs\n",
    "    for i in range(0, n_reps):\n",
    "        rf = sklearn.ensemble.RandomForestClassifier(n_estimators=50, random_state=i)\n",
    "        rf.fit(X, y)\n",
    "        s = rf.feature_importances_\n",
    "        importances[i] = s\n",
    "        assert numpy.isclose(numpy.sum(s), 1.0), numpy.sum(s)\n",
    "    \n",
    "    return numpy.mean(importances, axis=0)\n",
    "\n",
    "def extract_feature_scores(X, y, scorers):\n",
    "    ret = []\n",
    "    X = sklearn.preprocessing.MinMaxScaler().fit_transform(X)\n",
    "    for f in scorers:\n",
    "        scores = numpy.array(f(X, y))\n",
    "        if scores.shape[0] == 2:\n",
    "            scores = scores[0] # drop p-values\n",
    "        # normalize it\n",
    "        scores = scores/scores.sum()\n",
    "        ret.append(scores)\n",
    "    return numpy.array(ret)\n",
    "\n",
    "def select_k_best(scores, n):\n",
    "    return numpy.argsort(scores)[:n]\n",
    "\n",
    "def univariate_candidates(models, features_length, scores):\n",
    "    candidates = []\n",
    "    for n_features in features_length:\n",
    "        \n",
    "        for (m,p) in models:\n",
    "            # individual scoring functions\n",
    "            for scores in feature_scores:\n",
    "                cand = ( m, p, select_k_best(scores, n_features), 'k-best' )\n",
    "                candidates.append(cand)\n",
    "\n",
    "            # combined univariate score\n",
    "            scores = numpy.mean(feature_scores, axis=0)\n",
    "            assert scores.shape[0] == 1425\n",
    "            candidates.append((m, p, select_k_best(scores, n_features), 'k-best-mean'))\n",
    "\n",
    "    return candidates\n",
    "\n",
    "feature_scorers = [\n",
    "    sklearn.feature_selection.mutual_info_classif,\n",
    "    sklearn.feature_selection.f_classif,\n",
    "    sklearn.feature_selection.chi2,\n",
    "]\n",
    "feature_scores = extract_feature_scores(*get_XY(fulldata), feature_scorers)\n",
    "assert feature_scores.shape[1] == 1425\n",
    "univariate_candidates(models, (1,), feature_scores);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot feature scores, each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1425)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Forward Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "def sfs_candidates(dataset, models, features_length):\n",
    "    candidates = []\n",
    "    \n",
    "    estimators = {\n",
    "        'RF': sklearn.ensemble.RandomForestClassifier(n_estimators=1, max_depth=5),\n",
    "        'kNN1': sklearn.neighbors.KNeighborsClassifier(n_neighbors=1),\n",
    "    }\n",
    "    for name, estimator in estimators.items():\n",
    "        max_features = max(features_length)\n",
    "        sfs = SequentialFeatureSelector(estimator, k_features=max_features, forward=True, floating=False,\n",
    "                                        cv=5, scoring='accuracy', verbose=1, n_jobs=2)\n",
    "        X, y = get_XY(dataset)\n",
    "        sfs.fit(X, y)\n",
    "\n",
    "        # Also evaluate shorter combinations of the best K\n",
    "        for n_features in features_length:\n",
    "            features = sfs.k_feature_idx_[:n_features]\n",
    "    \n",
    "            for (m, p) in models:\n",
    "                candidates.append((m, p, features, 'sfs'))\n",
    "        \n",
    "    return candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_features_candidates(models):\n",
    "    candidates = []\n",
    "    for (m, p) in models:\n",
    "        candidates.append(( m, p, None, 'all'))\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  80 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=2)]: Done 680 tasks      | elapsed:   35.5s\n",
      "[Parallel(n_jobs=2)]: Done 1425 out of 1425 | elapsed:  1.0min finished\n",
      "Features: 1/5[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  88 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=2)]: Done 388 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=2)]: Done 888 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=2)]: Done 1424 out of 1424 | elapsed:   55.6s finished\n",
      "Features: 2/5[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done 172 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=2)]: Done 772 tasks      | elapsed:   33.5s\n",
      "[Parallel(n_jobs=2)]: Done 1420 out of 1423 | elapsed:   59.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=2)]: Done 1423 out of 1423 | elapsed:   59.1s finished\n",
      "Features: 3/5[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done 172 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=2)]: Done 772 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=2)]: Done 1422 out of 1422 | elapsed:   50.2s finished\n",
      "Features: 4/5[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  88 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=2)]: Done 388 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=2)]: Done 888 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=2)]: Done 1418 out of 1421 | elapsed:   51.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=2)]: Done 1421 out of 1421 | elapsed:   51.0s finished\n",
      "Features: 5/5[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done 256 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=2)]: Done 1156 tasks      | elapsed:   32.1s\n",
      "[Parallel(n_jobs=2)]: Done 1425 out of 1425 | elapsed:   39.4s finished\n",
      "Features: 1/5[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done 256 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=2)]: Done 1156 tasks      | elapsed:   33.4s\n",
      "[Parallel(n_jobs=2)]: Done 1424 out of 1424 | elapsed:   40.7s finished\n",
      "Features: 2/5[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done 164 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=2)]: Done 764 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=2)]: Done 1420 out of 1423 | elapsed:   39.8s remaining:    0.1s\n",
      "[Parallel(n_jobs=2)]: Done 1423 out of 1423 | elapsed:   39.9s finished\n",
      "Features: 3/5[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done 166 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=2)]: Done 766 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=2)]: Done 1422 out of 1422 | elapsed:   41.8s finished\n",
      "Features: 4/5[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done 164 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=2)]: Done 764 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=2)]: Done 1421 out of 1421 | elapsed:   42.3s finished\n",
      "Features: 5/5"
     ]
    },
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_lengths = (1, 2, 3, 5)\n",
    "\n",
    "candidates = [] + \\\n",
    "    all_features_candidates(models) + \\\n",
    "    sfs_candidates(fulldata, models, feature_lengths) + \\\n",
    "    univariate_candidates(models, feature_lengths, feature_scores) + \\\n",
    "    random_candidates(models, feature_lengths, n_random=3)\n",
    "\n",
    "#numpy.random.shuffle(candidates)\n",
    "\n",
    "#for cand in candidates:\n",
    "#    print('cand', cand[2], type(cand[0]), cand[3])\n",
    "\n",
    "len(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r 0 2.084718704223633 1.0248916149139404\n",
      "r 1 6.966068267822266 24.16402244567871\n",
      "r 2 15.762321710586548 29.390678882598877\n",
      "r 3 0.19814515113830566 0.477435827255249\n",
      "r 4 4.3473076820373535 2.2692883014678955\n",
      "r 5 0.10947847366333008 0.4569723606109619\n",
      "r 6 0.21562695503234863 0.5062267780303955\n",
      "r 7 4.224099636077881 5.673119068145752\n",
      "r 8 0.11412620544433594 0.4493098258972168\n",
      "r 9 0.1999976634979248 0.4817383289337158\n",
      "r 10 4.209441900253296 2.2678630352020264\n",
      "r 11 0.11828470230102539 0.4352104663848877\n",
      "r 12 0.19657182693481445 0.47269773483276367\n",
      "r 13 4.245086908340454 2.2173268795013428\n",
      "r 14 0.12880897521972656 0.4442102909088135\n",
      "r 15 0.1919546127319336 0.4736363887786865\n",
      "r 16 4.442005634307861 17.888440132141113\n",
      "r 17 0.10945630073547363 0.41867780685424805\n",
      "r 18 0.1938788890838623 0.47275352478027344\n",
      "r 19 4.432848215103149 18.10808539390564\n",
      "r 20 0.11419034004211426 0.4246981143951416\n",
      "r 21 0.19411563873291016 0.47847437858581543\n",
      "r 22 4.423448801040649 18.285876274108887\n",
      "r 23 0.11889433860778809 0.44220495223999023\n",
      "r 24 0.19819164276123047 0.4799044132232666\n",
      "r 25 4.467008113861084 18.177617073059082\n",
      "r 26 0.12569189071655273 0.45334649085998535\n",
      "r 27 0.2002699375152588 0.4751718044281006\n",
      "r 28 0.19476962089538574 0.47518372535705566\n",
      "r 29 0.19550323486328125 0.4906039237976074\n",
      "r 30 0.19576001167297363 0.4720642566680908\n",
      "r 31 4.571475267410278 5.806130647659302\n",
      "r 32 4.602811574935913 17.97421932220459\n",
      "r 33 4.31831693649292 5.671430587768555\n",
      "r 34 4.644847869873047 18.11581826210022\n",
      "r 35 0.10859322547912598 0.4253690242767334\n",
      "r 36 0.11199545860290527 0.4491465091705322\n",
      "r 37 0.10880637168884277 0.4174463748931885\n",
      "r 38 0.10805225372314453 0.4481992721557617\n",
      "r 39 0.19498753547668457 0.48009443283081055\n",
      "r 40 0.1936509609222412 0.468766450881958\n",
      "r 41 0.19419503211975098 0.4755673408508301\n",
      "r 42 0.19551944732666016 0.4686157703399658\n",
      "r 43 4.271702766418457 2.179929256439209\n",
      "r 44 4.493007659912109 18.453888177871704\n",
      "r 45 4.433137893676758 5.769589900970459\n",
      "r 46 4.409729719161987 6.063745498657227\n",
      "r 47 0.11221528053283691 0.42459726333618164\n",
      "r 48 0.11084151268005371 0.41901159286499023\n",
      "r 49 0.11207246780395508 0.43464207649230957\n",
      "r 50 0.1099083423614502 0.4256904125213623\n",
      "r 51 0.1954035758972168 0.47684240341186523\n",
      "r 52 0.19476032257080078 0.4734838008880615\n",
      "r 53 0.19493961334228516 0.4739973545074463\n",
      "r 54 0.19546031951904297 0.47170186042785645\n",
      "r 55 4.560563325881958 17.908885717391968\n",
      "r 56 4.331324815750122 2.260956048965454\n",
      "r 57 4.5180933475494385 17.934441566467285\n",
      "r 58 4.331425189971924 2.1813416481018066\n",
      "r 59 0.11452364921569824 0.48052477836608887\n",
      "r 60 0.1131124496459961 0.45357251167297363\n",
      "r 61 0.11834430694580078 0.4654257297515869\n",
      "r 62 0.1174769401550293 0.46142578125\n",
      "r 63 0.21312522888183594 0.4940624237060547\n",
      "r 64 0.21944761276245117 0.4817180633544922\n",
      "r 65 0.2159898281097412 0.4923515319824219\n",
      "r 66 0.22066044807434082 0.477384090423584\n",
      "r 67 4.63674521446228 18.70647430419922\n",
      "r 68 4.44738245010376 2.3783724308013916\n",
      "r 69 4.569381237030029 18.590428829193115\n",
      "r 70 4.391252756118774 5.858392000198364\n",
      "r 71 0.12215518951416016 0.44083213806152344\n",
      "r 72 0.11881589889526367 0.43390917778015137\n",
      "r 73 0.12295818328857422 0.44726085662841797\n",
      "r 74 0.11925077438354492 0.43892407417297363\n",
      "r 75 0.19143939018249512 0.47072696685791016\n",
      "r 76 4.51892876625061 18.167558670043945\n",
      "r 77 0.11001348495483398 0.4490499496459961\n",
      "r 78 0.23334646224975586 0.4784109592437744\n",
      "r 79 4.357353448867798 2.2004618644714355\n",
      "r 80 0.10950422286987305 0.46474647521972656\n",
      "r 81 0.19443082809448242 0.4724116325378418\n",
      "r 82 4.539006948471069 18.89995837211609\n",
      "r 83 0.13701748847961426 0.4159419536590576\n",
      "r 84 0.19525575637817383 0.47254419326782227\n",
      "r 85 4.337257385253906 2.2439849376678467\n",
      "r 86 0.11417269706726074 0.41747379302978516\n",
      "r 87 0.19429874420166016 0.4820711612701416\n",
      "r 88 4.416555404663086 2.356579542160034\n",
      "r 89 0.11757564544677734 0.4631462097167969\n",
      "r 90 0.20579957962036133 0.5254249572753906\n",
      "r 91 4.48101019859314 2.2576851844787598\n",
      "r 92 0.11667656898498535 0.44880032539367676\n",
      "r 93 0.19690895080566406 0.4747323989868164\n",
      "r 94 4.571820259094238 18.163278102874756\n",
      "r 95 0.11763191223144531 0.43381190299987793\n",
      "r 96 0.19438672065734863 0.4725966453552246\n",
      "r 97 4.270668029785156 2.1821577548980713\n",
      "r 98 0.11818981170654297 0.43679141998291016\n",
      "r 99 0.19589734077453613 0.47377490997314453\n",
      "r 100 4.326827764511108 5.764646053314209\n",
      "r 101 0.11668181419372559 0.46663665771484375\n",
      "r 102 0.2114419937133789 0.49541521072387695\n",
      "r 103 4.284359455108643 2.2106778621673584\n",
      "r 104 0.12478280067443848 0.4497535228729248\n",
      "r 105 0.1956923007965088 0.473010778427124\n",
      "r 106 4.293924808502197 5.772554397583008\n",
      "r 107 0.12370443344116211 0.4620974063873291\n",
      "r 108 0.20315051078796387 0.4857761859893799\n",
      "r 109 4.487522602081299 5.91216254234314\n",
      "r 110 0.12513184547424316 0.45145273208618164\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i, candidate in enumerate(candidates):\n",
    "    selector = candidate[3] \n",
    "    r = evaluate_candidate(fulldata, candidate[:3], n_tests=10)\n",
    "    assert len(r) == 5, len(r)\n",
    "    print('r', i, r[3], r[4])\n",
    "    results.append((candidate, r, selector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_mean</th>\n",
       "      <th>test_std</th>\n",
       "      <th>train_mean</th>\n",
       "      <th>train_std</th>\n",
       "      <th>n_features</th>\n",
       "      <th>features</th>\n",
       "      <th>model</th>\n",
       "      <th>feature_selector</th>\n",
       "      <th>gridsearch_time</th>\n",
       "      <th>evaluation_time</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.921472</td>\n",
       "      <td>0.061590</td>\n",
       "      <td>0.942076</td>\n",
       "      <td>0.038910</td>\n",
       "      <td>5.0</td>\n",
       "      <td>(28, 128, 138, 189, 279)</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>sfs</td>\n",
       "      <td>0.198192</td>\n",
       "      <td>0.479904</td>\n",
       "      <td>{'n_neighbors': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.885327</td>\n",
       "      <td>0.063180</td>\n",
       "      <td>0.917890</td>\n",
       "      <td>0.050091</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(28, 128, 138)</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>sfs</td>\n",
       "      <td>0.194116</td>\n",
       "      <td>0.478474</td>\n",
       "      <td>{'n_neighbors': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.878279</td>\n",
       "      <td>0.080978</td>\n",
       "      <td>0.919950</td>\n",
       "      <td>0.051033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>all</td>\n",
       "      <td>6.966068</td>\n",
       "      <td>24.164022</td>\n",
       "      <td>{'min_samples_leaf': 0.01, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.873203</td>\n",
       "      <td>0.078614</td>\n",
       "      <td>0.898022</td>\n",
       "      <td>0.054612</td>\n",
       "      <td>5.0</td>\n",
       "      <td>(28, 128, 138, 189, 279)</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>sfs</td>\n",
       "      <td>4.467008</td>\n",
       "      <td>18.177617</td>\n",
       "      <td>{'min_samples_leaf': 0.01, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.870601</td>\n",
       "      <td>0.074146</td>\n",
       "      <td>0.897546</td>\n",
       "      <td>0.040627</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(28, 128, 138)</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>sfs</td>\n",
       "      <td>4.423449</td>\n",
       "      <td>18.285876</td>\n",
       "      <td>{'min_samples_leaf': 0.01, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.849200</td>\n",
       "      <td>0.082641</td>\n",
       "      <td>0.902962</td>\n",
       "      <td>0.071322</td>\n",
       "      <td>5.0</td>\n",
       "      <td>(103, 138, 444, 1354, 1391)</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>sfs</td>\n",
       "      <td>4.245087</td>\n",
       "      <td>2.217327</td>\n",
       "      <td>{'min_samples_leaf': 0.01, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.832461</td>\n",
       "      <td>0.070709</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.059637</td>\n",
       "      <td>2.0</td>\n",
       "      <td>(103, 138)</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>sfs</td>\n",
       "      <td>0.215627</td>\n",
       "      <td>0.506227</td>\n",
       "      <td>{'n_neighbors': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.829501</td>\n",
       "      <td>0.071691</td>\n",
       "      <td>0.864949</td>\n",
       "      <td>0.057481</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[482, 565, 548, 837, 768]</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>random</td>\n",
       "      <td>4.293925</td>\n",
       "      <td>5.772554</td>\n",
       "      <td>{'min_samples_leaf': 0.01, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.814082</td>\n",
       "      <td>0.071508</td>\n",
       "      <td>0.877037</td>\n",
       "      <td>0.056838</td>\n",
       "      <td>5.0</td>\n",
       "      <td>(103, 138, 444, 1354, 1391)</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>sfs</td>\n",
       "      <td>0.196572</td>\n",
       "      <td>0.472698</td>\n",
       "      <td>{'n_neighbors': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.809731</td>\n",
       "      <td>0.080311</td>\n",
       "      <td>0.842623</td>\n",
       "      <td>0.074854</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[482, 565, 548, 837, 768]</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>random</td>\n",
       "      <td>0.195692</td>\n",
       "      <td>0.473011</td>\n",
       "      <td>{'n_neighbors': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test_mean  test_std  train_mean  train_std  n_features  \\\n",
       "24    0.921472  0.061590    0.942076   0.038910         5.0   \n",
       "21    0.885327  0.063180    0.917890   0.050091         3.0   \n",
       "1     0.878279  0.080978    0.919950   0.051033         NaN   \n",
       "25    0.873203  0.078614    0.898022   0.054612         5.0   \n",
       "22    0.870601  0.074146    0.897546   0.040627         3.0   \n",
       "13    0.849200  0.082641    0.902962   0.071322         5.0   \n",
       "6     0.832461  0.070709    0.876923   0.059637         2.0   \n",
       "106   0.829501  0.071691    0.864949   0.057481         5.0   \n",
       "12    0.814082  0.071508    0.877037   0.056838         5.0   \n",
       "105   0.809731  0.080311    0.842623   0.074854         5.0   \n",
       "\n",
       "                        features                   model feature_selector  \\\n",
       "24      (28, 128, 138, 189, 279)    KNeighborsClassifier              sfs   \n",
       "21                (28, 128, 138)    KNeighborsClassifier              sfs   \n",
       "1                           None  RandomForestClassifier              all   \n",
       "25      (28, 128, 138, 189, 279)  RandomForestClassifier              sfs   \n",
       "22                (28, 128, 138)  RandomForestClassifier              sfs   \n",
       "13   (103, 138, 444, 1354, 1391)  RandomForestClassifier              sfs   \n",
       "6                     (103, 138)    KNeighborsClassifier              sfs   \n",
       "106    [482, 565, 548, 837, 768]  RandomForestClassifier           random   \n",
       "12   (103, 138, 444, 1354, 1391)    KNeighborsClassifier              sfs   \n",
       "105    [482, 565, 548, 837, 768]    KNeighborsClassifier           random   \n",
       "\n",
       "     gridsearch_time  evaluation_time  \\\n",
       "24          0.198192         0.479904   \n",
       "21          0.194116         0.478474   \n",
       "1           6.966068        24.164022   \n",
       "25          4.467008        18.177617   \n",
       "22          4.423449        18.285876   \n",
       "13          4.245087         2.217327   \n",
       "6           0.215627         0.506227   \n",
       "106         4.293925         5.772554   \n",
       "12          0.196572         0.472698   \n",
       "105         0.195692         0.473011   \n",
       "\n",
       "                                             params  \n",
       "24                               {'n_neighbors': 1}  \n",
       "21                               {'n_neighbors': 1}  \n",
       "1    {'min_samples_leaf': 0.01, 'n_estimators': 10}  \n",
       "25   {'min_samples_leaf': 0.01, 'n_estimators': 10}  \n",
       "22   {'min_samples_leaf': 0.01, 'n_estimators': 10}  \n",
       "13   {'min_samples_leaf': 0.01, 'n_estimators': 10}  \n",
       "6                                {'n_neighbors': 1}  \n",
       "106  {'min_samples_leaf': 0.01, 'n_estimators': 10}  \n",
       "12                               {'n_neighbors': 1}  \n",
       "105                              {'n_neighbors': 1}  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores = numpy.array([r[1][0] for r in results])\n",
    "train_scores = numpy.array([r[1][1] for r in results])\n",
    "\n",
    "def n_features(r):\n",
    "    f = r[0][2]\n",
    "    if f is None:\n",
    "        return None\n",
    "    else:\n",
    "        return len(f)\n",
    "\n",
    "def selected_params(r):\n",
    "    cv_results = r[1][2]\n",
    "    return pandas.DataFrame(cv_results).sort_values('mean_test_score').params[0]\n",
    "\n",
    "df = pandas.DataFrame({\n",
    "    'test_mean': test_scores.mean(axis=1),\n",
    "    'test_std': test_scores.std(axis=1),\n",
    "    'train_mean': train_scores.mean(axis=1),\n",
    "    'train_std': train_scores.std(axis=1),\n",
    "    'n_features': [ n_features(r) for r in results ],\n",
    "    'features': [ r[0][2] for r in results ],\n",
    "    'model': [ str(type(r[0][0]).__name__) for r in results ],\n",
    "    'feature_selector': [ r[2] for r in results ],\n",
    "    'gridsearch_time': [ r[1][3] for r in results ],\n",
    "    'evaluation_time': [ r[1][4] for r in results ],\n",
    "    'params': [ selected_params(r) for r in results ],\n",
    "})\n",
    "df.sort_values(by='test_mean', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist('test_mean', bins=10, by=['n_features'], figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist('test_mean', bins=10, by=['model'], figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist('test_mean', bins=10, by=['feature_selector'], figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
