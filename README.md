
# Master of Data Science

Studying machine learning, data mining, applied statistics.
At Norwegian University of Life Sciences ([NMBU](https://nmbu.no)).

## Research

### [Machine Learning for Embedded Systems](./embeddedml)

## Courses

### [INF121](https://github.com/jonnor/bike-sharing-oslo)

### [INF200](https://bitbucket.org/jonnor/inf200_jonnordby)

### [INF221](./inf221)

### [INF250](./inf250)

### [DAT200](./dat200)

### [TEL240](./tel240)

### [INF230](./inf230)

## Interesting specializations

Techniques: Intelligent embedded systems, robotics, computer vision, simulation.
Applications: Renewable energy, sustainability, automation/processindustry

Robotics

* [TEL240 Control Engineering and Automation](https://www.nmbu.no/course/tel240). Spring. 10p
* [TEL250 Introduction to robotics and automation](https://www.nmbu.no/emne/TEL250). January block. 5p
* [TMPP350C Prosessregulation](https://www.nmbu.no/emne/TMPP350C). Pass/no, 5p, autumn seminar. !requires TEL240
* [INF4380 - Introduksjon til robotteknologi](http://www.uio.no/studier/emner/matnat/ifi/INF4380/index.html). Spring, 10p
* [UNIK4490 - Control of manipulators and mobile robots](http://www.uio.no/studier/emner/matnat/its/UNIK4490/index-eng.html). Autumn, 10p
* [UNIK4570 - Robust multivariabel regulering](http://www.uio.no/studier/emner/matnat/its/UNIK4570/index.html)
* [UNIK4950 - Multiagent-systemer](http://www.uio.no/studier/emner/matnat/its/UNIK4950/index.html). Autumn, 10p
* [INF5040 - Åpen distribuert prosessering](http://www.uio.no/studier/emner/matnat/ifi/INF5040/index.html). Autumn, 10p

Computer vision

* [UNIK4690 - Maskinsyn](http://www.uio.no/studier/emner/matnat/its/UNIK4690/index.html). Spring. 10p. Project-based evaluation
* [INF5860 - Maskinlæring for bildeanalyse](http://www.uio.no/studier/emner/matnat/ifi/INF5860/index.html). Spring. 10p.
* [UNIK4590 - Pattern Recognition](http://www.uio.no/studier/emner/matnat/its/UNIK4590/index-eng.html). Autumn, 10p

Renewable energy

* [FYS375 Energy Technology](https://www.nmbu.no/emne/FYS375), lab-oriented
* [FORN200 Renewable Energy](https://www.nmbu.no/emne/FORN200). Autumn, 10p
* [FORN330 Renewable Energy analysis](https://www.nmbu.no/emne/FORN330). Autumn, 10p
* [UNIK4800 - Renewable Energy: science and technology](http://www.uio.no/studier/emner/matnat/its/UNIK4800/index.html). Autumn, 10p
* [UNIK4830 - Solenergisystemer](http://www.uio.no/studier/emner/matnat/its/UNIK4830/index.html). Spring, 10p
* [INF5870 - Energiinformatikk](http://www.uio.no/studier/emner/matnat/ifi/INF5870/index.html). Spring, 10p. Project and oral exam
* [UNIK4820 - Energisystemanalyse: Modellering, metoder og scenarioer](http://www.uio.no/studier/emner/matnat/its/UNIK4820/index.html). Spring,10p

Foundations

* [MNKOM4000 - Formidling og vitenskapsjournalistikk](http://www.uio.no/studier/emner/matnat/ibv/MNKOM4000/index.html). Pass/not, 10p, weekly tasks. Spring
* [UNIK4660 - Visualisering av vitenskapelige data](http://www.uio.no/studier/emner/matnat/its/UNIK4660/index.html)
* [IN5000 - Qualitative Research Methods](http://www.uio.no/studier/emner/matnat/ifi/IN5000/index.html)
* [TMP261 Varme og strømningssimulering](https://www.nmbu.no/emne/TMP261)
* [FYS251 Varmeoverføring og energi](https://www.nmbu.no/emne/fys251)
* [STAT210 Design of Experiments and Analysis of Variance](https://www.nmbu.no/course/STAT210). 5p, August block

Construction

* [TIP200 Produktutvikling og produktdesign med 3D](https://www.nmbu.no/emne/tip200). Autumn, 10p. Project-based evaluation
* [TBM200 Material Science](https://www.nmbu.no/emne/TBM200). Autumn, 10p
* [KJM-MENA5555 - Polymerer og makromolekyler](http://www.uio.no/studier/emner/matnat/kjemi/KJM-MENA5555/index.html)
* [TBM250 Finite Element Method](https://www.nmbu.no/emne/TBM250). !Requires [TBM120](https://www.nmbu.no/emne/TBM120), 10p, autumn.
* [TBA210 Building Structures II](https://www.nmbu.no/course/TBA210).
!Requires [TBA190](https://www.nmbu.no/course/TBA190)
* [TBA331 Building Performance Simulation](https://www.nmbu.no/course/TBA331)
!Requires TBA210
* [TBA222 Konstruksjonsteknikk stål og tre](https://www.nmbu.no/emne/tba222). !Requires TBM120

## PhD

[Positions in Norway](https://www.finn.no/job/fulltime/search.html?occupation=0.13&q=data)

Topics

* Robotics
* Sustainability
* Renewable energy
* Internet of Things, Embedded Systems
* Automation.
* CAD/CAM
* Blockchain


## Ideas

Flowhub related

* From Jupyter to cloud-scale service using msgflo-python
* FBP/NoFlo execution for Jupyter. Kernel?. .fbp renderer, component/JavaScript evaluator
* Integrated data visualization for programming,
[dataviz](https://github.com/jonnor/projects/tree/master/introspectable-computing/dataviz)

Basic data science applications

* Energy usage at Bitraf/c-base, relative to weather. Anomaly detection, reporting/monitoring
* CNC usage at Bitraf. How many of the jobs/parts can be done on a 60x120 cm workarea machine.
Take gcode/dxfs from Dropbox, analyse.
* Predicting likelyhood of someone opening for guests upon ringing the doorbell.

Machine learning

* Assist in reverse engineering of protocols, for example for machine control (Shopbot,Redsail).
Record input, output pairs. Change input parameters, find corresponding change in output.

Larger projects, potentially novel

* Machine-vision-assisted construction of CAD models. Reverse engineering
[smart-cad](https://github.com/jonnor/projects/tree/master/smart-cad).
Bunch of research already done, both planar models.
Maybe possible to focus on making more practical via smartphone camera

* Automation of CAM paths for maximizing material usage and waste management. Machine-vision
Automatic part layout of useful parts in remainder of cutsheet for CNC/laser.
Automatic creation of cutlines to discard pieces smaller than w,h.
Can a greedy algorithm perform well for part layout, ie does the problem have optimal substructure?

* Component-based PCB autolayout & routing
Reusable modules with pre-laidout schematic/board snippets for a given functionality.
Autolayout by placing modules as black-box rectangles/polygons.
Using reduction in netlist size (implicit ignoring local connections) for better autorouting.
But this can be detected via strongly connected components of the graph?
Note, one can also use [Planarity_testing](https://en.wikipedia.org/wiki/Planarity_testing) to determine subgraphs
which can be laid out without 
Using contraints to express requirements, solving to autosuggest sub-circuit solutions.
http://www.electronicdesign.com/what-s-difference-between/what-s-difference-pcb-routing-then-and-now

Robotics

* Analyzing low-cost motion systems.
Using force-sensors on motors/actuator/effector and recording data at high speed
Perform tests on running different kind of jobs.
Measure: static/dynamic friction, coefficient.
Forces due to acceleration.
Forces working back on effector (CNC milling).
Slop. Backlash.
Compare with simulated data, detect anomalies.
Compare different technologies/techniques .
Use to guide development of ultra-low-cost, reprap-style, motion systems.
Note, friction coefficient very dependent on how tight bearings are.
Slop/precision also dependent on this. Especially for plain-bearings.
Should at least measure slop. For instance measure force needed to rotate N degrees?
Could try to tune slop to be same for doing comparative studies?
HEX711 IC commonly used only allows for 80 samples/second.
Would need. A load-cell is a Weathstone bridge, so an instrumentation amplifier is way to go.
ADC can be done in a fast microcontroller. STM32 etc.
Example circuit based on INA125, instrumentation amp with precision voltage reference included:
http://www.mechtechplace.net/mech-tech-electronics/building-a-low-cost-strain-gage-load-cell-amplifier/
INA125 has 4.5kHz bandwith @ 100x gain, should be good for 1k+ samples/second.

Detect failures modes in CNC machining though a model-based approach:
Generate from the CAM files the expected load conditions and compare it continiously, detect and flag anomalies. 
* [Tool breakage detection in CNC high-speed milling based in feed-motor current signals](https://link.springer.com/article/10.1007/s00170-010-2907-9). 
* [Prediction of Cutting Force in 3-Axis CNC Milling Machines Based on Voxelization Framework for Digital Manufacturing](https://ac.els-cdn.com/S2351978915010227/1-s2.0-S2351978915010227-main.pdf?_tid=abd03b3c-bcf8-419f-8e85-6b3b5870b1e8&acdnat=1521660091_5873ea8ff3d1ea396b558157776a4981)

Big themes

Sustainability

* Energy production
* Recycling, waste-management
* Manufacturing, low-scale automation. Cheap robotics and deployment. CAD/CAM improvements
* Agriculture, food-production
* Understanding and predicting impacts (economic,social,environmental)


## Publishing

[Open Hardware Journal](https://openhardware.metajnl.com/about/#hardware-metapapers)

Is TapeCore/Doverail/fabricatable-machines publishable in Open Hardware Journal?
Could I do the work as a 5-point self-organized topic (ie in robotics)?
Can/should I use NMBU as affiliation? Would they sponsor the publishing costs?
Would/should there be research uses at NMBU for testing practical application?

[Brage @ NMBU](https://www.nmbu.no/en/about-nmbu/library/publishing/brage). Open Access publishing for NMBU affiliates. 
Note: NMBU operates an internal publishing fund for Open Access publications, up to 15k NOK for publication.

[ArXiv](https://arxiv.org). Pre-print / working paper publishing. Widely used open/free source of papers.

[Hackaday Journal](https://journal.hackaday.io/submissions). Possiblity of presenting at the Hackaday Superconference.

[Modelling, Identidication and Control](http://www.mic-journal.no/), Nordic journal. Open Access.

## Conferences

* Fablab conference. July. FAB14 in France, http://www.fab14.org/
* Open Source Hardware conference.
* FOSDEM. February, Brussels
* Libre Graphics Meeting. 2018, Seville
* Linux Audio Conference. 2018, June, Berlin
* DAFX. 2018, September, Aveiro Portugal.
[CFP March 29](https://www.mail-archive.com/sursound@music.vt.edu/msg09198.html)
* [EuroPython 2018](https://ep2018.europython.eu/), Edinbourgh, July. CFP opens in March/April.
* EuroSciPy 2018. August 28 - September 1, Trento, Italy. CFP not open as of March
* [ECDA 2018](https://euads.org/events/ecda-2018/). Paderborn, Germany, 4th – 6th July, 2018.
* Vipimage. 2018 not announced yet
* Open Source Summit Europe 2018. Oct 22-24, Edinbourgh.
[CFP until June 30](https://events.linuxfoundation.org/events/open-source-summit-europe-2018/program/cfp/)
* Embedded Linux Conference Europe. [CFP until June 30](https://events.linuxfoundation.org/events/elce-2018/program/cfp/)
* European Conference on Computer Vision. [2018](https://eccv2018.org/dates/), September, Munich



## Inbox

* [Hadley Wickham: Tidy data](http://vita.had.co.nz/papers/tidy-data.html).
This paper tackles a small, but important, component of data cleaning: data tidying.

Huge amount of Computer Science papers: https://github.com/papers-we-love/papers-we-love

## References

Books

* [The Elements of Statistical Learning](https://web.stanford.edu/~hastie/Papers/ESLII.pdf).
Recommended by Kristin T. regarding classification, regression methods.

Lectures

* [Statistical Computing for Scientists and Engineers, U.Notre Dame](https://www.zabaras.com/statisticalcomputing).
Dense syllabus: from Bayesian Statistics, many Monte Carlo methods, and Uncertainty Quantification.

Web

* [Relationship between Ridge regression and PCA regression](https://stats.stackexchange.com/questions/81395/relationship-between-ridge-regression-and-pca-regression)
* [Relationship between SVD and PCA. How to use SVD to perform PCA?](https://stats.stackexchange.com/questions/134282/relationship-between-svd-and-pca-how-to-use-svd-to-perform-pca)
* [How Are Principal Component Analysis and Singular Value Decomposition Related](https://intoli.com/blog/pca-and-svd/)
* [pandas](http://pandas.pydata.org/), Python package for analysing large amounts of data
* [Clever Machines Learn How to Be Curious](https://www.quantamagazine.org/clever-machines-learn-how-to-be-curious-20170919/).
Rewarding agents for curiosity, exploring their environment and preferring actions which they can least confidently predict.
In this way being able to learn to perform tasks without predefined goal and associated cost function.
* [Feature Visualization: How neural networks build up their understanding of images](https://distill.pub/2017/feature-visualization/).
Starting with feeding in noise, and then optimizing the response for some parameter (neuron, channel, logits.).
Discusses this approach versus finding representative examples in a dataset.
Using a 'diversity' term to optimization objective that pushes multiple examples to be different from eachother.
Optimizing for pairs of neurons, interpolating between them.
Discussed multiple existing approaches to regularization of the model to give representative results.
Broadly classified into: Frequency penalization, transformation robustness, learned priors.
Can also use preconditioning: transformations on the gradient. Can give good results in fewer steps, and reduces high-frequency impact
Paper presentation: Nice semi-interactive image galleries where one can adjust parameters and it gives results at that combo.
* [Eliezer Yudkowsky – AI Alignment: Why It's Hard, and Where to Start](https://www.youtube.com/watch?v=EUjc1WuyPT8).
Utility functions for intelligent agent behavior, challenges and ways to deal with.
Recent work in progress:
Utility indifference. Agent must respect an off/suspend switch. Paper: Corrigibility
Low impact: Agents that deliberately reduce their agency on the world. Paper: Reduced Impact Artificial Intelligence
Ambiguity indentification. Have the AI ask you about using new capabilities. Paper: The Value Learning Problem
Conservatism. Creating robust boundaries/space between desired and non-desired classifications,
such that new capabilities/stategries will fall on right side. Conservative white-listing instead of black-listing.
Specifying environmental goals using sensory data. What if AI is like modern machine learning. Paper: Formalizing Two Problems in Realistic World-Models. Being able to express environmental goals instead of just goals in terms of directly observable sensory input.
Inverse reinforcement learning. Watch another agent, induce what it wants. Paper: Learning the preference of Bounded Agents.
Act-based agent. Supervised learning by observing human behavior/strategies.
Mild optimization. Don't optimize your utility function so hard/narrow.
Recent completed work:
AXAI. How to create an AGI given unbounded computation. Paper: Universal Algorithmic Intelligence
Intelligent software agent cooperation. Program Equilibrium in the Prisoners Dilemma via Lobs Theorem.
Probabilitic game theory. Paper: Reflective oracles.
* [Deep reinforcement for robotics](https://www.facebook.com/nipsfoundation/videos/1554594181298482)
Reinforcement learning is different from supervised methods. The agent observes its environment and performs actions on it.
It observes the outcome of its actions and compares this with desired outcome.
Current RL algorithms are fully generic (mathematically). They can get superhuman performance, but the learning efficiency is very low.
Can we make it more efficient by making use of particular information about the environment. Ie: obey our laws of physics
Can we meta-reinformcement learn? That let the agent learn to reinformcement learn?
Using Recurrent Neural Net as a generic compute achitecture, with both compute and storage ability. 
Evaluating on Multi-armed bandit problem, and known asymptomatically optimall algorithm.
Currently meta-learning works 2/3 of the time. Reasons for not working inlclude overfitting (or underfitting), and insufficient signal.
Model-Agnostic Meta-Learning.
Imitation learning. Many success stories in robotics. Human shows how to perform task, agent learns the policy.
Lifelong learning. Instead of only training/learning up-front, will learn continiously after deployment.
Simulation is very important. Huge advantages to training in real world.
Challenge is for the learnings in simulation to transfer over into real world.
One approach is randomized simulation domains. With enough variation - even when not high fidelity,
allows to train agent which performs well on real-life scenario without any real-life training data.
How to increase signal for reinformement learning?
Hindsight Experience Replay. Also learn from failures. Inject goals into old experiences
* [Amit's thoughts on pathfinding](http://theory.stanford.edu/~amitp/GameProgramming/Heuristics.html).
Detailed and well explained use of A* for pathfinding in games, including practical considerations.
Chosing heuristics function, its values. Tie breaking, data structures, making behavior interesting
* [Visual foresight](https://sites.google.com/view/visual-foresight).
Robots using real-time predictions of the visual/camera stimuly to learn how to perform tasks.
* [Bilateral_Filtering](http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/MANDUCHI1/Bilateral_Filtering.html).
When performed in CIE-Lab gives very natural blurring, not introducing new colors. Also preserves edges and shadows well.
Can be applied iteratively, which effectively reduces the amount of colors present. Reducing/removing texture.
Could be used as a pre-processing step to color quantize an image? 
* [Optimizing fixed-point FIR filters](https://se.mathworks.com/help/dsp/examples/optimized-fixed-point-fir-filters.html),
by quantizing filter coefficients.  
* [dspguru FIR implementation](https://dspguru.com/dsp/faqs/fir/implementation/), some tricks in C
* [TIIR filters](https://ccrma.stanford.edu/~jos/tiirts/TIIR_Filters.html), truncated IIRs.
Using two IIRs to get the response of an FIR filter, but with fewer calculations.
* Search a problemsolving for fully-observable,deterministic,known environments.
Solution is a sequence of actions that lead to the goal.
`SMA*`, simplified memory-limited A* graph search. Optimal with *admissible* heuristic, and a robust solution for many problems.
Challenge is in defining a good heuristic function (and meaningful path distances).
Must be non-negative, never overestimate, respect 'triangle equality', and h(goal) = 0.
The heuristic determines overall performance, and can be evaluated by looking at the effective branching factor on example problems.
How many nodes are evaluated versus path length to reach a solution. Should be quite small.
One method for developing heuristic is to transform the problem to a simplified version, by removing restrictions/rules.
If the problem is defined in a formal language, it is possible to automatically derive such simplified versions.
One can use a composed heuristic function which takes the max of a family of heuristic functions.
Heuristics can also be made using a database of solutions to subproblems.
Heuristics can be learned by creating a prediction model between feature(s) of a state and the distance to the goal.
When using multiple features, often use linear weighted combinations to get one number. 
= Chapter 3, AI A Modern Approach. 

Dealing with lack of (labeled) data

* Self learning. [Using Pseudo labeling for semi-supervised learning](https://towardsdatascience.com/simple-explanation-of-semi-supervised-learning-and-pseudo-labeling-c2218e8c769b). After having trained model on labeled data, run it on the unlabeled data to get (pseudo) labels, then train it on the combined setup. Up to 25% pseudo labels in a batch. When method provides confidence score, take only the most confident samples into training set.
Also called .
* Semi-supervised learning can be done using a generative model, like Gaussian mixture, Naive Bayes, Hidden Markov.
Cluster-and-label: Use a clustering algorithm (unsupervised), take the labels of the majority of labeled data.
[Introduction to semi-supervised learning](http://pages.cs.wisc.edu/~jerryzhu/pub/sslicml07.pdf).
Can define a graph of similarities.
* Co-training. Semi-supervised learning. Each sample is encoded with two strong and different features, ie text and image.
Train one classifier per feature, then have the two classifiers teach eachother. Multiview 
* Active learning. Training phase done in batches, most important/pivotal candidates then labeled.
[Novak 2010](http://vhosts.eecs.umich.edu/ssp2012/nowak.pdf), active learning using binary search in low-rank embedding space.
* Generative Adverserial learning. Is/can it be used outside of GAN?
* Human/user-in-the-loop. Ask the user about the correct label
* Synthesising samples. Oversampling: duplicate some samples as-is.
Randomly sample attributes.
SMOTE, especially for balancing minority classes.
* Data augmentation. Creating new samples based on peturbations of originals.
Example: [librosa sound augmentation](https://www.kaggle.com/huseinzol05/sound-augmentation-librosa)
* Programmatic supervision. Distant supervision. 
* Weak supervision. [Data Programming](http://dawn.cs.stanford.edu/pubs/snorkel-nips2016.pdf)
generates labels that are noisy and possibly conflicting, then learns the inaccuracies.

Datasets / data sources

* [libsvm](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/).
Standardized format with some 50 small to medium dataset examples, covering classification, regression.
* [mldata.org](http://mldata.org/). Some 800 datasets, searchable with tags.


