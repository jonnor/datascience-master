{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sklearn\n",
    "import pandas\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import trackml.dataset\n",
    "import trackml.score\n",
    "\n",
    "import os.path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hit_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>volume_id</th>\n",
       "      <th>layer_id</th>\n",
       "      <th>module_id</th>\n",
       "      <th>particle_id</th>\n",
       "      <th>tx</th>\n",
       "      <th>ty</th>\n",
       "      <th>tz</th>\n",
       "      <th>tpx</th>\n",
       "      <th>tpy</th>\n",
       "      <th>tpz</th>\n",
       "      <th>weight</th>\n",
       "      <th>event_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-64.409897</td>\n",
       "      <td>-7.163700</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-64.411598</td>\n",
       "      <td>-7.164120</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>250710.000000</td>\n",
       "      <td>-149908.000000</td>\n",
       "      <td>-956385.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-55.336102</td>\n",
       "      <td>0.635342</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22525763437723648</td>\n",
       "      <td>-55.338501</td>\n",
       "      <td>0.630805</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>-0.570605</td>\n",
       "      <td>0.028390</td>\n",
       "      <td>-15.49220</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-83.830498</td>\n",
       "      <td>-1.143010</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-83.828003</td>\n",
       "      <td>-1.145580</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>626295.000000</td>\n",
       "      <td>-169767.000000</td>\n",
       "      <td>-760877.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-96.109100</td>\n",
       "      <td>-8.241030</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>297237712845406208</td>\n",
       "      <td>-96.122902</td>\n",
       "      <td>-8.230360</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>-0.225235</td>\n",
       "      <td>-0.050968</td>\n",
       "      <td>-3.70232</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-62.673599</td>\n",
       "      <td>-9.371200</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>418835796137607168</td>\n",
       "      <td>-62.659401</td>\n",
       "      <td>-9.375040</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>-0.281806</td>\n",
       "      <td>-0.023487</td>\n",
       "      <td>-6.57318</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hit_id          x         y       z  volume_id  layer_id  module_id  \\\n",
       "0       1 -64.409897 -7.163700 -1502.5          7         2          1   \n",
       "1       2 -55.336102  0.635342 -1502.5          7         2          1   \n",
       "2       3 -83.830498 -1.143010 -1502.5          7         2          1   \n",
       "3       4 -96.109100 -8.241030 -1502.5          7         2          1   \n",
       "4       5 -62.673599 -9.371200 -1502.5          7         2          1   \n",
       "\n",
       "          particle_id         tx        ty      tz            tpx  \\\n",
       "0                   0 -64.411598 -7.164120 -1502.5  250710.000000   \n",
       "1   22525763437723648 -55.338501  0.630805 -1502.5      -0.570605   \n",
       "2                   0 -83.828003 -1.145580 -1502.5  626295.000000   \n",
       "3  297237712845406208 -96.122902 -8.230360 -1502.5      -0.225235   \n",
       "4  418835796137607168 -62.659401 -9.375040 -1502.5      -0.281806   \n",
       "\n",
       "             tpy           tpz    weight  event_id  \n",
       "0 -149908.000000 -956385.00000  0.000000      1000  \n",
       "1       0.028390     -15.49220  0.000010      1000  \n",
       "2 -169767.000000 -760877.00000  0.000000      1000  \n",
       "3      -0.050968      -3.70232  0.000008      1000  \n",
       "4      -0.023487      -6.57318  0.000009      1000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_train = 'train_100_events.zip'\n",
    "event_prefix = \"event000001001\"\n",
    "#path = os.path.join(path_to_train, event_prefix)\n",
    "path = 'train_sample.zip'\n",
    "\n",
    "events = pandas.DataFrame()\n",
    "datas = []\n",
    "for e in trackml.dataset.load_dataset(path, nevents=3):\n",
    "    event_id, hits, cells, particles, truth = e\n",
    "    data = hits.merge(truth)\n",
    "    data['event_id'] = event_id\n",
    "    events = data\n",
    "    datas.append(data)\n",
    "events = pandas.concat(datas)\n",
    "\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1000, 1001, 1002]), 340123)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events['event_id'].unique(), len(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 9, 3186)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(events['layer_id'].unique()), len(events['volume_id'].unique()), len(events['module_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hit_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>volume_id</th>\n",
       "      <th>layer_id</th>\n",
       "      <th>module_id</th>\n",
       "      <th>particle_id</th>\n",
       "      <th>tx</th>\n",
       "      <th>ty</th>\n",
       "      <th>tz</th>\n",
       "      <th>tpx</th>\n",
       "      <th>tpy</th>\n",
       "      <th>tpz</th>\n",
       "      <th>weight</th>\n",
       "      <th>event_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-55.336102</td>\n",
       "      <td>0.635342</td>\n",
       "      <td>-1502.500000</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22525763437723648</td>\n",
       "      <td>-55.338501</td>\n",
       "      <td>0.630805</td>\n",
       "      <td>-1502.500000</td>\n",
       "      <td>-0.570605</td>\n",
       "      <td>0.028390</td>\n",
       "      <td>-15.49220</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>1420</td>\n",
       "      <td>-55.162201</td>\n",
       "      <td>0.604841</td>\n",
       "      <td>-1497.500000</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>106</td>\n",
       "      <td>22525763437723648</td>\n",
       "      <td>-55.154400</td>\n",
       "      <td>0.621779</td>\n",
       "      <td>-1497.500000</td>\n",
       "      <td>-0.569794</td>\n",
       "      <td>0.027264</td>\n",
       "      <td>-15.49280</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>-47.975498</td>\n",
       "      <td>0.311848</td>\n",
       "      <td>-1302.500000</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>22525763437723648</td>\n",
       "      <td>-47.988098</td>\n",
       "      <td>0.315591</td>\n",
       "      <td>-1302.500000</td>\n",
       "      <td>-0.568883</td>\n",
       "      <td>0.021994</td>\n",
       "      <td>-15.49290</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3169</th>\n",
       "      <td>3170</td>\n",
       "      <td>-47.812302</td>\n",
       "      <td>0.327322</td>\n",
       "      <td>-1297.500000</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>106</td>\n",
       "      <td>22525763437723648</td>\n",
       "      <td>-47.804100</td>\n",
       "      <td>0.308733</td>\n",
       "      <td>-1297.500000</td>\n",
       "      <td>-0.571445</td>\n",
       "      <td>0.020847</td>\n",
       "      <td>-15.49330</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3233</th>\n",
       "      <td>3234</td>\n",
       "      <td>-40.622799</td>\n",
       "      <td>0.088046</td>\n",
       "      <td>-1102.500000</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>22525763437723648</td>\n",
       "      <td>-40.626099</td>\n",
       "      <td>0.087326</td>\n",
       "      <td>-1102.500000</td>\n",
       "      <td>-0.569940</td>\n",
       "      <td>0.015274</td>\n",
       "      <td>-15.49340</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5342</th>\n",
       "      <td>5343</td>\n",
       "      <td>-40.438801</td>\n",
       "      <td>0.098098</td>\n",
       "      <td>-1097.500000</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>106</td>\n",
       "      <td>22525763437723648</td>\n",
       "      <td>-40.442200</td>\n",
       "      <td>0.082538</td>\n",
       "      <td>-1097.500000</td>\n",
       "      <td>-0.570204</td>\n",
       "      <td>0.013872</td>\n",
       "      <td>-15.49400</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>5424</td>\n",
       "      <td>-35.480598</td>\n",
       "      <td>-0.008800</td>\n",
       "      <td>-962.500000</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>22525763437723648</td>\n",
       "      <td>-35.475899</td>\n",
       "      <td>-0.024284</td>\n",
       "      <td>-962.500000</td>\n",
       "      <td>-0.569773</td>\n",
       "      <td>0.010668</td>\n",
       "      <td>-15.49400</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5481</th>\n",
       "      <td>5482</td>\n",
       "      <td>-35.330101</td>\n",
       "      <td>-0.023294</td>\n",
       "      <td>-958.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>22525763437723648</td>\n",
       "      <td>-35.310101</td>\n",
       "      <td>-0.027160</td>\n",
       "      <td>-958.000000</td>\n",
       "      <td>-0.571644</td>\n",
       "      <td>0.008881</td>\n",
       "      <td>-15.49490</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7866</th>\n",
       "      <td>7867</td>\n",
       "      <td>-35.312302</td>\n",
       "      <td>-0.004440</td>\n",
       "      <td>-957.500000</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>106</td>\n",
       "      <td>22525763437723648</td>\n",
       "      <td>-35.291698</td>\n",
       "      <td>-0.027451</td>\n",
       "      <td>-957.500000</td>\n",
       "      <td>-0.571617</td>\n",
       "      <td>0.009012</td>\n",
       "      <td>-15.49500</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7950</th>\n",
       "      <td>7951</td>\n",
       "      <td>-30.333700</td>\n",
       "      <td>-0.105277</td>\n",
       "      <td>-822.500000</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>22525763437723648</td>\n",
       "      <td>-30.315399</td>\n",
       "      <td>-0.095482</td>\n",
       "      <td>-822.500000</td>\n",
       "      <td>-0.570993</td>\n",
       "      <td>0.006231</td>\n",
       "      <td>-15.49510</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25163</th>\n",
       "      <td>25164</td>\n",
       "      <td>13.459300</td>\n",
       "      <td>-29.124300</td>\n",
       "      <td>123.259003</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>133</td>\n",
       "      <td>22525763437723648</td>\n",
       "      <td>13.473700</td>\n",
       "      <td>-29.119301</td>\n",
       "      <td>123.247002</td>\n",
       "      <td>0.146668</td>\n",
       "      <td>-0.337037</td>\n",
       "      <td>1.52506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25257</th>\n",
       "      <td>25258</td>\n",
       "      <td>13.994600</td>\n",
       "      <td>-30.318600</td>\n",
       "      <td>128.675995</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>134</td>\n",
       "      <td>22525763437723648</td>\n",
       "      <td>13.994200</td>\n",
       "      <td>-30.318899</td>\n",
       "      <td>128.673004</td>\n",
       "      <td>0.145511</td>\n",
       "      <td>-0.337405</td>\n",
       "      <td>1.52505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       hit_id          x          y            z  volume_id  layer_id  \\\n",
       "1           2 -55.336102   0.635342 -1502.500000          7         2   \n",
       "1419     1420 -55.162201   0.604841 -1497.500000          7         2   \n",
       "1459     1460 -47.975498   0.311848 -1302.500000          7         4   \n",
       "3169     3170 -47.812302   0.327322 -1297.500000          7         4   \n",
       "3233     3234 -40.622799   0.088046 -1102.500000          7         6   \n",
       "5342     5343 -40.438801   0.098098 -1097.500000          7         6   \n",
       "5423     5424 -35.480598  -0.008800  -962.500000          7         8   \n",
       "5481     5482 -35.330101  -0.023294  -958.000000          7         8   \n",
       "7866     7867 -35.312302  -0.004440  -957.500000          7         8   \n",
       "7950     7951 -30.333700  -0.105277  -822.500000          7        10   \n",
       "25163   25164  13.459300 -29.124300   123.259003          8         2   \n",
       "25257   25258  13.994600 -30.318600   128.675995          8         2   \n",
       "\n",
       "       module_id        particle_id         tx         ty           tz  \\\n",
       "1              1  22525763437723648 -55.338501   0.630805 -1502.500000   \n",
       "1419         106  22525763437723648 -55.154400   0.621779 -1497.500000   \n",
       "1459           1  22525763437723648 -47.988098   0.315591 -1302.500000   \n",
       "3169         106  22525763437723648 -47.804100   0.308733 -1297.500000   \n",
       "3233           1  22525763437723648 -40.626099   0.087326 -1102.500000   \n",
       "5342         106  22525763437723648 -40.442200   0.082538 -1097.500000   \n",
       "5423           1  22525763437723648 -35.475899  -0.024284  -962.500000   \n",
       "5481           4  22525763437723648 -35.310101  -0.027160  -958.000000   \n",
       "7866         106  22525763437723648 -35.291698  -0.027451  -957.500000   \n",
       "7950           1  22525763437723648 -30.315399  -0.095482  -822.500000   \n",
       "25163        133  22525763437723648  13.473700 -29.119301   123.247002   \n",
       "25257        134  22525763437723648  13.994200 -30.318899   128.673004   \n",
       "\n",
       "            tpx       tpy       tpz    weight  event_id  \n",
       "1     -0.570605  0.028390 -15.49220  0.000010      1000  \n",
       "1419  -0.569794  0.027264 -15.49280  0.000008      1000  \n",
       "1459  -0.568883  0.021994 -15.49290  0.000006      1000  \n",
       "3169  -0.571445  0.020847 -15.49330  0.000005      1000  \n",
       "3233  -0.569940  0.015274 -15.49340  0.000005      1000  \n",
       "5342  -0.570204  0.013872 -15.49400  0.000006      1000  \n",
       "5423  -0.569773  0.010668 -15.49400  0.000009      1000  \n",
       "5481  -0.571644  0.008881 -15.49490  0.000011      1000  \n",
       "7866  -0.571617  0.009012 -15.49500  0.000014      1000  \n",
       "7950  -0.570993  0.006231 -15.49510  0.000016      1000  \n",
       "25163  0.146668 -0.337037   1.52506  0.000000      1002  \n",
       "25257  0.145511 -0.337405   1.52505  0.000000      1002  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[events['particle_id'] == 22525763437723648]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hit_id', 'x', 'y', 'z', 'volume_id', 'layer_id', 'module_id',\n",
       "       'particle_id', 'tx', 'ty', 'tz', 'tpx', 'tpy', 'tpz', 'weight',\n",
       "       'event_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def single_features(hits):\n",
    "    \n",
    "    # From DBSCAN benchmark\n",
    "    # https://www.kaggle.com/mikhailhushchyn/dbscan-benchmark\n",
    "    x = hits.x.values\n",
    "    y = hits.y.values\n",
    "    z = hits.z.values\n",
    "    xy_scale = numpy.sqrt(x**2 + y**2 + z**2)\n",
    "    xnorm = x/xy_scale\n",
    "    ynorm = y/xy_scale\n",
    "    z_scale = numpy.sqrt(x**2 + y**2)\n",
    "    znorm = z/z_scale\n",
    "    \n",
    "    nn = StandardScaler().fit_transform([xnorm, ynorm, znorm])\n",
    "    features = pandas.DataFrame({\n",
    "        'particle_id': hits['particle_id'],\n",
    "        'xnorm': nn[0],\n",
    "        'ynorm': nn[1],\n",
    "        'znorm': nn[2],\n",
    "    })\n",
    "    \n",
    "    return features\n",
    "\n",
    "hits = single_features(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640000, 9)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample hits for training, a mix of hits from same track and from different\n",
    "def make_pairs(df):\n",
    "    p = (df.merge(df, on=df.assign(key_col=1)['key_col'], suffixes=('_a', '_b'))\n",
    "      #.query('hit_id_b != hit_id_a') # filter out joins on the same row\n",
    "      .reset_index(drop=True))\n",
    "    return p\n",
    "\n",
    "def training_sample(hits, n_particles, n_hits=5, random_state=None):\n",
    "    particles = hits['particle_id'].sample(n=n_particles, random_state=random_state)\n",
    "    samples = []\n",
    "    for particle in particles:\n",
    "        matches = hits[hits['particle_id'] == particle].sample(n=n_hits, replace=True, random_state=random_state)\n",
    "        #nonmatches = hits[hits['particle_id'] != particle].sample(n=n_hits//2, replace=True, random_state=random_state)\n",
    "        samples.append(matches)\n",
    "        #samples.append(nonmatches)\n",
    "\n",
    "    samples = pandas.concat(samples)\n",
    "    return samples\n",
    "\n",
    "def sample_pairs(n_particles, random_state=None):\n",
    "    t = training_sample(hits, n_particles, random_state=random_state)\n",
    "    pairs = make_pairs(t)\n",
    "    pairs['matches'] = pairs['particle_id_a'] == pairs['particle_id_b']\n",
    "    return pairs\n",
    "\n",
    "def equalize_matches(pairs):\n",
    "    add = pairs.shape[0]\n",
    "    match_equalizer = pairs[pairs.matches==True].sample(n=add, replace=True)\n",
    "    pairs = pandas.concat([pairs, match_equalizer])\n",
    "    return pairs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640000, 7)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pair_features(pairs): \n",
    "    features = pandas.DataFrame()\n",
    "\n",
    "    # Distance\n",
    "    features['xd'] = pairs['xnorm_a'] - pairs['xnorm_b']\n",
    "    features['yd'] = pairs['ynorm_a'] - pairs['ynorm_b']\n",
    "    features['zd'] = pairs['znorm_a'] - pairs['znorm_b']\n",
    "    \n",
    "    # Position\n",
    "    features['xa'] = pairs['xnorm_a']\n",
    "    features['ya'] = pairs['ynorm_a']\n",
    "    features['za'] = pairs['znorm_a']\n",
    "    \n",
    "    # Target\n",
    "    features['matches'] = pairs['matches']\n",
    "    \n",
    "    return features\n",
    "\n",
    "pairs = sample_pairs(40, random_state=2)\n",
    "data = pair_features(pairs)\n",
    "data.shape, data.matches.mean()\n",
    "\n",
    "#data[data.matches==False].head(n=2)\n",
    "#data[data.matches==True].head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[['xd', 'yd', 'zd']].groupby(data['matches']).hist(figsize=(16,8), bins=40, alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From http://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=numpy.linspace(.1, 1.0, 5), metric=None):\n",
    "    np = numpy\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    \n",
    "    s = model_selection.learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring=metric)\n",
    "    train_sizes, train_scores, test_scores = s\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forest_importance(forest, X):\n",
    "    importances = forest.feature_importances_\n",
    "    std = numpy.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "    indices = numpy.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(X.shape[1]):\n",
    "        print(\"%d. %d : %s (%f)\" % (f + 1, indices[f], X.columns[indices[f]], importances[indices[f]]), )\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    ax.set_title(\"Feature importances\")\n",
    "    ax.bar(range(X.shape[1]), importances[indices],\n",
    "           color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    #ax.set_xticks(range(X.shape[1]), indices)\n",
    "    #ax.set_xlim([-1, X.shape[1]])\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5187611607142857 0.037447916666666664\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] min_samples_split=0.01, n_estimators=80 .........................\n",
      "[CV] .......... min_samples_split=0.01, n_estimators=80, total= 2.8min\n",
      "[CV] min_samples_split=0.01, n_estimators=80 .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... min_samples_split=0.01, n_estimators=80, total= 3.0min\n",
      "[CV] min_samples_split=0.01, n_estimators=80 .........................\n",
      "[CV] .......... min_samples_split=0.01, n_estimators=80, total= 2.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  9.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using parameters {'min_samples_split': 0.01, 'n_estimators': 80}\n",
      "Test set score: 0.54\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, clf, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ExtraTreesClassifier' object has no attribute 'decision_function'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-f20ccd0a7f6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test set score: %.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mplot_learning_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Learning curve'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-50-b6faff07492a>\u001b[0m in \u001b[0;36mplot_learning_curve\u001b[0;34m(estimator, title, X, y, ylim, cv, n_jobs, train_sizes, metric)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mtrain_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtrain_scores_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mlearning_curve\u001b[0;34m(estimator, X, y, groups, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose, shuffle, random_state)\u001b[0m\n\u001b[1;32m   1126\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m             verbose, parameters=None, fit_params=None, return_train_score=True)\n\u001b[0;32m-> 1128\u001b[0;31m             for train, test in train_test_proportions)\n\u001b[0m\u001b[1;32m   1129\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0mn_cv_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mn_unique_ticks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, clf, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFrxJREFUeJzt3XuQJWWd5vHvAw1eEGFXGi/QAjM2\nQouOYIE64wizoAPsLIQ7htKBN5YBxxXnomEsO7OLiBrrdQydaUPahRmUFcHLaIeijBcUUVAKRQS0\nZ1pEafHSysULCIK//eNk0Weqq946XXRWne7+fiI6IjPPm5m/83bVeSrfPJmZqkKSpNnssNgFSJLG\nm0EhSWoyKCRJTQaFJKnJoJAkNRkUkqQmg0KaQ5JPJnnxYtchLZZ4HYXGVZKbgD+rqs8sdi3S9swj\nCm3XkixZ7BoeqG3hPWi8GRTaKiX5kyTXJLk9yZeTPGnotdOTfCfJL5LckOQ5Q6+9JMmXkrw9ya3A\nmd2yy5O8NcltSb6b5JihdT6f5M+G1m+13S/JZd2+P5NkVZLzG+/j+O59/Lyr+ehu+U1Jjhpqd+bU\ndpLsm6SSnJzk+8DnknwqyWnTtv2NJP+1mz4gyaeT3JpkbZLnzb/3tb0xKLTVSXIIcC7wUuARwNnA\nmiQP6pp8B/hDYDfgtcD5SR49tImnAjcCewJvGFq2FtgDeDNwTpLMUkKr7fuBr3Z1nQm8sPE+DgPe\nC7wa2B14JnDTXO9/yOHAgcAfd/tdObTtFcA+wCeS7AJ8umuzZ9fuXUmesBn70nbMoNDW6BTg7Kr6\nSlXdV1XnAXcDTwOoqg9W1S1V9duquhD4N+CwofVvqaq/r6p7q+qubtn3quo9VXUfcB7waOCRs+x/\nxrZJHgscCpxRVfdU1eXAmsb7OBk4t6o+3dX6g6r69mb0w5lV9avuPfwz8OQk+3SvnQh8pKruBv4E\nuKmq/rF7z18DPgw8dzP2pe2YQaGt0T7Aq7php9uT3A4sAx4DkORFQ8NStwMHMfjrf8rNM2zzR1MT\nVXVnN/mwWfY/W9vHALcOLZttX1OWMTj6ma/7t11VvwA+AZzQLToB+H/d9D7AU6f114nAox7AvrUd\n8SSYtkY3A2+oqjdMf6H7i/o9wJHAFVV1X5JrgOFhpL6+6vdD4D8meehQWCxrtL8Z+N1ZXvsV8NCh\n+Zk+1Ke/jwuA1yS5DHgIcOnQfr5QVc9qFS/NxiMKjbudkjx46N8SBkHw50memoFdkvznJLsCuzD4\nAN0AkOQkBkcUvauq7wGTDE6Q75zk6cB/aaxyDnBSkiOT7JBkryQHdK9dA5yQZKckE4w2THQxg6OH\ns4ALq+q33fKPA/sneWG3vZ2SHJrkwPm8T21/DAqNu4uBu4b+nVlVkwzOU/wDcBuwDngJQFXdALwN\nuAL4MfBE4EsLWO+JwNOBnwGvBy5kcP5kE1X1VeAk4O3AHcAXGHzQA/xvBkcbtzE4If/+uXbcnY/4\nCHDUcPtuWOrZDIajbmEwdPYm4EEzbEbahBfcST1KciHw7ap6zWLXIs2XRxTSFtQN6fxuN5R0NHA8\n8NHFrkt6IHoLiiTnJvlJkutmeT1J3plkXZJru+/GS1u7RwGfB34JvBN4WVV9fVErkh6g3oaekjyT\nwS/Le6tqk5OJSY4FXgEcy+ACpndU1VN7KUaSNG+9HVFU1WXArY0mxzMIkaqqK4Hdp109K0kaA4t5\nHcVe/PuLkdZ3y344vWGSU4FTAXbZZZenHHDAAdObSJIarr766p9W1dL5rLuYQTHTfXRmHAerqtXA\naoCJiYmanJzssy5J2uYk+d58113Mbz2t599ftbo3g+94S5LGyGIGxRrgRd23n54G3FFVmww7SZIW\nV29DT0kuAI4A9kiyHngNsBNAVb2bwRW3xzK4qvZOBleoSpLGTG9BUVUr53i9gJf3tX9J0pbhldmS\npCaDQpLUZFBIkpoMCklSk0EhSWoyKCRJTQaFJKnJoJAkNRkUkqQmg0KS1GRQSJKaDApJUpNBIUlq\nMigkSU0GhSSpyaCQJDUZFJKkJoNCktRkUEiSmgwKSVKTQSFJajIoJElNBoUkqcmgkCQ1GRSSpCaD\nQpLUZFBIkpoMCklSk0EhSWoyKCRJTQaFJKnJoJAkNRkUkqQmg0KS1GRQSJKaeg2KJEcnWZtkXZLT\nZ3j9sUkuTfL1JNcmObbPeiRJm6+3oEiyI7AKOAZYAaxMsmJas/8FXFRVBwMnAO/qqx5J0vz0eURx\nGLCuqm6sqnuADwDHT2tTwMO76d2AW3qsR5I0D30GxV7AzUPz67tlw84EXpBkPXAx8IqZNpTk1CST\nSSY3bNjQR62SpFn0GRSZYVlNm18J/FNV7Q0cC7wvySY1VdXqqpqoqomlS5f2UKokaTZ9BsV6YNnQ\n/N5sOrR0MnARQFVdATwY2KPHmiRJm6nPoLgKWJ5kvyQ7MzhZvWZam+8DRwIkOZBBUDi2JEljpLeg\nqKp7gdOAS4BvMfh20/VJzkpyXNfsVcApSb4BXAC8pKqmD09JkhbRkj43XlUXMzhJPbzsjKHpG4A/\n6LMGSdID45XZkqQmg0KS1GRQSJKaDApJUpNBIUlqMigkSU0GhSSpyaCQJDUZFJKkJoNCktRkUEiS\nmgwKSVKTQSFJajIoJElNBoUkqcmgkCQ1GRSSpCaDQpLUZFBIkpoMCklSk0EhSWoyKCRJTQaFJKnJ\noJAkNRkUkqQmg0KS1GRQSJKaDApJUpNBIUlqMigkSU0GhSSpyaCQJDUZFJKkJoNCktTUa1AkOTrJ\n2iTrkpw+S5vnJbkhyfVJ3t9nPZKkzbekrw0n2RFYBTwLWA9clWRNVd0w1GY58D+BP6iq25Ls2Vc9\nkqT56fOI4jBgXVXdWFX3AB8Ajp/W5hRgVVXdBlBVP+mxHknSPPQZFHsBNw/Nr++WDdsf2D/Jl5Jc\nmeTomTaU5NQkk0kmN2zY0FO5kqSZ9BkUmWFZTZtfAiwHjgBWAv83ye6brFS1uqomqmpi6dKlW7xQ\nSdLs+gyK9cCyofm9gVtmaPOxqvpNVX0XWMsgOCRJY6LPoLgKWJ5kvyQ7AycAa6a1+SjwRwBJ9mAw\nFHVjjzVJkjZTb0FRVfcCpwGXAN8CLqqq65OcleS4rtklwM+S3ABcCry6qn7WV02SpM2XqumnDcbb\nxMRETU5OLnYZkrRVSXJ1VU3MZ12vzJYkNRkUkqQmg0KS1GRQSJKaDApJUtPIQZHkGUlO6qaXJtmv\nv7IkSeNipKBI8hrgfzC40yvATsD5fRUlSRofox5RPAc4DvgVQFXdAuzaV1GSpPExalDcU4Mr8wog\nyS79lSRJGiejBsVFSc4Gdk9yCvAZ4D39lSVJGhcjPeGuqt6a5FnAz4HHA2dU1ad7rUySNBbmDIru\nkaaXVNVRgOEgSduZOYeequo+4M4kuy1APZKkMTPS0BPwa+CbST5N980ngKr6i16qkiSNjVGD4hPd\nP0nSdmbUk9nndU+p279btLaqftNfWZKkcTFSUCQ5AjgPuAkIsCzJi6vqsv5KkySNg1GHnt4GPLuq\n1gIk2R+4AHhKX4VJksbDqBfc7TQVEgBV9a8M7vckSdrGjXpEMZnkHOB93fyJwNX9lCRJGiejBsXL\ngJcDf8HgHMVlwLv6KkqSND5GDYolwDuq6u/g/qu1H9RbVZKksTHqOYrPAg8Zmn8IgxsDSpK2caMG\nxYOr6pdTM930Q/spSZI0TkYNil8lOWRqJskEcFc/JUmSxsmo5yj+CvhgklsYPLzoMcDze6tKkjQ2\nmkcUSQ5N8qiqugo4ALgQuBf4FPDdBahPkrTI5hp6Ohu4p5t+OvA3wCrgNmB1j3VJksbEXENPO1bV\nrd3084HVVfVh4MNJrum3NEnSOJjriGLHJFNhciTwuaHXRj2/IUnais31YX8B8IUkP2XwLacvAiR5\nHHBHz7VJksZAMyiq6g1JPgs8GviXqqrupR2AV/RdnCRp8c05fFRVV86w7F/7KUeSNG5GveBOkrSd\nMigkSU29BkWSo5OsTbIuyemNds9NUt2tQSRJY6S3oOhuRb4KOAZYAaxMsmKGdrsyeM7FV/qqRZI0\nf30eURwGrKuqG6vqHuADwPEztHsd8Gbg1z3WIkmapz6DYi/g5qH59d2y+yU5GFhWVR9vbSjJqUkm\nk0xu2LBhy1cqSZpVn0GRGZbV/S8mOwBvB14114aqanVVTVTVxNKlS7dgiZKkufQZFOuBZUPzewO3\nDM3vChwEfD7JTcDTgDWe0Jak8dJnUFwFLE+yX5KdgROANVMvVtUdVbVHVe1bVfsCVwLHVdVkjzVJ\nkjZTb0FRVfcCpwGXAN8CLqqq65OcleS4vvYrSdqyer0DbFVdDFw8bdkZs7Q9os9aJEnz45XZkqQm\ng0KS1GRQSJKaDApJUpNBIUlqMigkSU0GhSSpyaCQJDUZFJKkJoNCktRkUEiSmgwKSVKTQSFJajIo\nJElNBoUkqcmgkCQ1GRSSpCaDQpLUZFBIkpoMCklSk0EhSWoyKCRJTQaFJKnJoJAkNRkUkqQmg0KS\n1GRQSJKaDApJUpNBIUlqMigkSU0GhSSpyaCQJDUZFJKkJoNCktTUa1AkOTrJ2iTrkpw+w+uvTHJD\nkmuTfDbJPn3WI0nafL0FRZIdgVXAMcAKYGWSFdOafR2YqKonAR8C3txXPZKk+enziOIwYF1V3VhV\n9wAfAI4fblBVl1bVnd3slcDePdYjSZqHPoNiL+Dmofn13bLZnAx8cqYXkpyaZDLJ5IYNG7ZgiZKk\nufQZFJlhWc3YMHkBMAG8ZabXq2p1VU1U1cTSpUu3YImSpLks6XHb64FlQ/N7A7dMb5TkKOBvgcOr\n6u4e65EkzUOfRxRXAcuT7JdkZ+AEYM1wgyQHA2cDx1XVT3qsRZI0T70FRVXdC5wGXAJ8C7ioqq5P\nclaS47pmbwEeBnwwyTVJ1syyOUnSIulz6Imquhi4eNqyM4amj+pz/5KkB84rsyVJTQaFJKnJoJAk\nNRkUkqQmg0KS1GRQSJKaDApJUpNBIUlqMigkSU0GhSSpyaCQJDUZFJKkJoNCktRkUEiSmgwKSVKT\nQSFJajIoJElNBoUkqcmgkCQ1GRSSpCaDQpLUZFBIkpoMCklSk0EhSWoyKCRJTQaFJKnJoJAkNRkU\nkqQmg0KS1GRQSJKaDApJUpNBIUlqMigkSU0GhSSpyaCQJDX1GhRJjk6yNsm6JKfP8PqDklzYvf6V\nJPv2WY8kafP1FhRJdgRWAccAK4CVSVZMa3YycFtVPQ54O/CmvuqRJM1Pn0cUhwHrqurGqroH+ABw\n/LQ2xwPnddMfAo5Mkh5rkiRtpiU9bnsv4Oah+fXAU2drU1X3JrkDeATw0+FGSU4FTu1m705yXS8V\nb332YFpfbcfsi43si43si40eP98V+wyKmY4Mah5tqKrVwGqAJJNVNfHAy9v62Rcb2Rcb2Rcb2Rcb\nJZmc77p9Dj2tB5YNze8N3DJbmyRLgN2AW3usSZK0mfoMiquA5Un2S7IzcAKwZlqbNcCLu+nnAp+r\nqk2OKCRJi6e3oafunMNpwCXAjsC5VXV9krOAyapaA5wDvC/JOgZHEieMsOnVfdW8FbIvNrIvNrIv\nNrIvNpp3X8Q/4CVJLV6ZLUlqMigkSU1jGxTe/mOjEfrilUluSHJtks8m2Wcx6lwIc/XFULvnJqkk\n2+xXI0fpiyTP6342rk/y/oWucaGM8Dvy2CSXJvl693ty7GLU2bck5yb5yWzXmmXgnV0/XZvkkJE2\nXFVj94/Bye/vAL8D7Ax8A1gxrc1/B97dTZ8AXLjYdS9iX/wR8NBu+mXbc1907XYFLgOuBCYWu+5F\n/LlYDnwd+A/d/J6LXfci9sVq4GXd9ArgpsWuu6e+eCZwCHDdLK8fC3ySwTVsTwO+Msp2x/WIwtt/\nbDRnX1TVpVV1Zzd7JYNrVrZFo/xcALwOeDPw64UsboGN0henAKuq6jaAqvrJAte4UEbpiwIe3k3v\nxqbXdG0Tquoy2teiHQ+8twauBHZP8ui5tjuuQTHT7T/2mq1NVd0LTN3+Y1szSl8MO5nBXwzbojn7\nIsnBwLKq+vhCFrYIRvm52B/YP8mXklyZ5OgFq25hjdIXZwIvSLIeuBh4xcKUNnY29/ME6PcWHg/E\nFrv9xzZg5PeZ5AXABHB4rxUtnmZfJNmBwV2IX7JQBS2iUX4uljAYfjqCwVHmF5McVFW391zbQhul\nL1YC/1RVb0vydAbXbx1UVb/tv7yxMq/PzXE9ovD2HxuN0hckOQr4W+C4qrp7gWpbaHP1xa7AQcDn\nk9zEYAx2zTZ6QnvU35GPVdVvquq7wFoGwbGtGaUvTgYuAqiqK4AHM7hh4PZmpM+T6cY1KLz9x0Zz\n9kU33HI2g5DYVsehYY6+qKo7qmqPqtq3qvZlcL7muKqa983QxtgovyMfZfBFB5LswWAo6sYFrXJh\njNIX3weOBEhyIIOg2LCgVY6HNcCLum8/PQ24o6p+ONdKYzn0VP3d/mOrM2JfvAV4GPDB7nz+96vq\nuEUruicj9sV2YcS+uAR4dpIbgPuAV1fVzxav6n6M2BevAt6T5K8ZDLW8ZFv8wzLJBQyGGvfozse8\nBtgJoKrezeD8zLHAOuBO4KSRtrsN9pUkaQsa16EnSdKYMCgkSU0GhSSpyaCQJDUZFJKkJoNCYyfJ\nI5Jc0/37UZIfDM3vPOI2/jHJ4+do8/IkJ26ZqsdDksuTPHmx69C2xa/HaqwlORP4ZVW9ddryMPj5\n3d5uwdCU5HLgtKq6ZrFr0bbDIwptNZI8Lsl1Sd4NfA14dJLVSSa75y2cMdT28iRPTrIkye1J3pjk\nG0muSLJn1+b1Sf5qqP0bk3y1e67B73fLd0ny4W7dC7p9bfIXe5JDk3whydVJPpnkkUl26uaf0bV5\nS5LXdtOvTXLV1PuZuvNxV8ffJfliBs+RmEjyz0n+rQvNqX64Psn7knwzyUVJHjJDTcd07/drGTy7\nZZehOqaeX/KmLfqfpG2SQaGtzQrgnKo6uKp+AJxeVRPA7wHPSrJihnV2A75QVb8HXAH8t1m2nao6\nDHg1MBU6rwB+1K37RuDgTVZKHgS8A/jTqnoKcD7wuqr6DYMrX1cneTbwn4DXd6u9o6oOBZ7Y1Td8\nZ9e7quoPGdx94KPAn3ftTk2y+1A/rKqqJzK4nfpLp9W0J3A6cGRVHQJcC/xlkkcyuDL3CVX1JOD/\nzNIX0v0MCm1tvlNVVw3Nr0zyNQZHGAcy+ACd7q6qmrr1+tXAvrNs+yMztHkGg+cbUFXfAK6fYb0D\ngScAn0lyDYMP6GXdOtd2638MOKkLDxg8P+WrDB6yc3i3/pSpW5F8E/hmVf24qn4N3MTGZ418t3ue\nAAyC6RnTavp9Bn3x5a6mE7v3dCvwWwa3s3gO8KtZ+kK631je60lquP+DLcly4C+Bw6rq9iTnM7jZ\n23T3DE3fx+w/93fP0GaUh2EFuLY7CpjJQQyelzI15PVQ4B+AQ6rqB0leP63uqTp+OzQ9NT9V1/ST\nizPdhv9TVfXCTYod3E33WQzuj/Yy4NmzvzXJIwpt3R4O/AL4eQZP6frjHvZxOfA8gCRPZOYjlhuA\nvZIc1rXbOckTuunnM7hh4xHAqiQPBx7C4EP/p0l2Bf50HnXtl+TQbnplV+ewLwOHJ/mdro5dkizv\n9vfw7sFOf80MQ2nSdB5RaGv2NQYf0tcxuH32l3rYx98D701ybbe/6xgcHdyvqu5O8lzgnd0H8RLg\nbUk2MDgncUR35HA28PaqOjnJed22vgd8ZR51XQ+ckuQc4NsMngk9XNOPk5wMXDj0leK/Ae4CPtKd\nV9kBeOU89q3tjF+PlRoyeCjWkqr6dTfU9S/A8u7xu4tV0+OAD1WV10toQXhEIbU9DPhsFxgBXrqY\nISEtBo8oJElNnsyWJDUZFJKkJoNCktRkUEiSmgwKSVLT/we/j5snQQ2hIQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import model_selection, metrics\n",
    "\n",
    "test_size = 0.3\n",
    "seed = 1\n",
    "\n",
    "target_columns = ['matches']\n",
    "data_columns = list(set(data.columns) - set(target_columns))\n",
    "\n",
    "s = model_selection.train_test_split(data[data_columns], data[target_columns], test_size=test_size, random_state=seed)\n",
    "X_train, X_test, Y_train, Y_test = s\n",
    "\n",
    "train = X_train\n",
    "train['matches'] = Y_train['matches']\n",
    "train = equalize_matches(train)\n",
    "X_train = train[data_columns]\n",
    "Y_train = train[target_columns]\n",
    "\n",
    "Y_train = Y_train['matches']\n",
    "Y_test = Y_test['matches']\n",
    "\n",
    "print(Y_train.mean(), Y_test.mean())\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "metric = 'average_precision'\n",
    "\n",
    "estimator = RandomForestClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [ 80 ],\n",
    "    'min_samples_split': [ 0.01 ],\n",
    "}\n",
    "search = model_selection.GridSearchCV(estimator, parameters, cv=3, verbose=2, scoring=metric)\n",
    "search.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluation\n",
    "print('Using parameters', search.best_params_)\n",
    "score = metrics.get_scorer(metric)(search.best_estimator_, X_test, Y_test)\n",
    "print('Test set score: %.2f' % (score,))\n",
    "\n",
    "plot_learning_curve(search.best_estimator_, 'Learning curve', X_train, Y_train, metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1565866860979545 0.8368567454798331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.99236199, 0.00763801],\n",
       "       [0.84341331, 0.15658669]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = metrics.get_scorer('precision')(search.best_estimator_, X_test, Y_test)\n",
    "recall = metrics.get_scorer('recall')(search.best_estimator_, X_test, Y_test)\n",
    "cm = metrics.confusion_matrix(search.best_estimator_.predict(X_test), Y_test)\n",
    "print(precision, recall)\n",
    "cm.astype('float') / cm.sum(axis=1)[:, numpy.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97883879, 0.02116121],\n",
       "       [0.88042041, 0.11957959]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pair_features(sample_pairs(20, random_state=11))\n",
    "b = pair_features(sample_pairs(20, random_state=12))\n",
    "c = pair_features(sample_pairs(20, random_state=13))\n",
    "validate = pandas.concat([a, b, c])\n",
    "X_valid = validate[data_columns]\n",
    "Y_valid = validate[target_columns]\n",
    "\n",
    "cm = metrics.confusion_matrix(search.best_estimator_.predict(X_valid), Y_valid)\n",
    "cm.astype('float') / cm.sum(axis=1)[:, numpy.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. 0 : yd (0.246868)\n",
      "2. 3 : xd (0.240406)\n",
      "3. 5 : zd (0.238469)\n",
      "4. 4 : za (0.115931)\n",
      "5. 1 : ya (0.084480)\n",
      "6. 2 : xa (0.073847)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3QAAAJOCAYAAAD/BkXEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUIIOAABgUP8P4Jg5CPcIDBMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3QAAAJOCAYAAAD/BkXEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUIIOAABgUP8P4Jg5CPcIDBMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_forest_importance(search.best_estimator_, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
