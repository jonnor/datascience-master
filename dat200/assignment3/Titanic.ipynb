{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics, model_selection, preprocessing, pipeline\n",
    "\n",
    "# ML methods\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From http://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=numpy.linspace(.1, 1.0, 5)):\n",
    "    np = numpy\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    \n",
    "    s = model_selection.learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_sizes, train_scores, test_scores = s\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>330911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>0</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>363272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Cabin Embarked    Fare                              Name  Parch  \\\n",
       "0  34.5   NaN        Q  7.8292                  Kelly, Mr. James      0   \n",
       "1  47.0   NaN        S  7.0000  Wilkes, Mrs. James (Ellen Needs)      0   \n",
       "\n",
       "   PassengerId  Pclass     Sex  SibSp  Survived  Ticket  \n",
       "0          892       3    male      0       NaN  330911  \n",
       "1          893       3  female      1       NaN  363272  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv = pandas.read_csv('./test.csv')\n",
    "train_csv = pandas.read_csv('./train.csv')\n",
    "raw = pandas.concat([test_csv, train_csv])\n",
    "raw[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Q', 'S', 'C', nan], dtype=object)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw['Embarked'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 3, 2, 4, 6, 5, 9])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw['Parch'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 8])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw['SibSp'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age             263\n",
       "Cabin          1014\n",
       "Embarked          2\n",
       "Fare              1\n",
       "Name              0\n",
       "Parch             0\n",
       "PassengerId       0\n",
       "Pclass            0\n",
       "Sex               0\n",
       "SibSp             0\n",
       "Survived        418\n",
       "Ticket            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "      <th>survived</th>\n",
       "      <th>sex_male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>34.5</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>47.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age    fare  survived  sex_male\n",
       "PassengerId                                  \n",
       "892          34.5  7.8292       NaN         1\n",
       "893          47.0  7.0000       NaN         0"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pandas.DataFrame({\n",
    "    'sex': raw['Sex'].astype('category'),\n",
    "    'age': raw['Age'],\n",
    "    'fare': raw['Fare'],\n",
    "    'survived': raw['Survived'],\n",
    "    #'sibsp': raw['SibSp'],\n",
    "    #'parch': raw['Parch'],\n",
    "    #'embarked': raw['Embarked'],\n",
    "})\n",
    "data.index=raw['PassengerId']\n",
    "data = pandas.get_dummies(data, columns=None, drop_first=True)\n",
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "without_result = data['survived'].isnull()\n",
    "has_result = ~without_result\n",
    "target_columns = ['survived']\n",
    "data_columns = list(set(data.columns) - set(target_columns))\n",
    "\n",
    "test_size = 0.3\n",
    "seed = 1\n",
    "s = model_selection.train_test_split(data[has_result][data_columns], data[has_result][target_columns], test_size=test_size, random_state=seed)\n",
    "X_train, X_test, Y_train, Y_test = s\n",
    "Y_train = Y_train['survived']\n",
    "Y_test = Y_test['survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 20 candidates, totalling 140 fits\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=20 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=20, total=   0.2s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=20 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=20, total=   0.1s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=20 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=20, total=   0.2s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=20 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=20, total=   0.2s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=20 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=20, total=   0.1s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=20 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=20, total=   0.1s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=20 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=20, total=   0.1s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=40 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=40, total=   0.3s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=40 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=40, total=   0.3s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=40 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=40, total=   0.3s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=40 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=40, total=   0.2s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=40 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=40, total=   0.3s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=40 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=40, total=   0.3s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=40 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=40, total=   0.3s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=60 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=60, total=   0.4s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=60 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=60, total=   0.4s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=60 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=60, total=   0.4s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=60 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=60, total=   0.4s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=60 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=60, total=   0.4s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=60 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=60, total=   0.3s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=60 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=60, total=   0.3s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=80 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=80, total=   0.5s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=80 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=80, total=   0.5s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=80 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=80, total=   0.5s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=80 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=80, total=   0.5s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=80 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=80, total=   0.5s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=80 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=80, total=   0.5s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=80 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=80, total=   0.5s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=100 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=100, total=   0.6s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=100 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=100, total=   0.6s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=100 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=100, total=   0.6s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=100 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=100, total=   0.6s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=100 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=100, total=   0.6s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=100 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=100, total=   0.7s\n",
      "[CV] randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=100 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.05, randomforestclassifier__n_estimators=100, total=   0.7s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=20 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=20, total=   0.1s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=20 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=20, total=   0.1s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=20 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=20, total=   0.1s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=20 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=20, total=   0.1s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=20 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=20, total=   0.1s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=20 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=20, total=   0.1s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=20 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=20, total=   0.1s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=40 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=40, total=   0.3s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=40 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=40, total=   0.2s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=40 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=40, total=   0.2s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=40 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=40, total=   0.2s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=40 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=40, total=   0.3s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=40 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=40, total=   0.2s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=40 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=40, total=   0.2s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=60 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=60, total=   0.4s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=60 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=60, total=   0.4s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=60 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=60, total=   0.4s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=60 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=60, total=   0.4s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=60 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=60, total=   0.4s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=60 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=60, total=   0.4s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=60 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=60, total=   0.4s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=80 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=80, total=   0.5s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=80 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=80, total=   0.5s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=80 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=80, total=   0.5s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=80 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=80, total=   0.5s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=80 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=80, total=   0.5s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=80 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=80, total=   0.5s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=80 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=80, total=   0.5s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=100 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=100, total=   0.6s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=100 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=100, total=   0.6s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=100 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=100, total=   0.6s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=100 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=100, total=   0.6s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=100 \n",
      "[CV]  randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=100, total=   0.6s\n",
      "[CV] randomforestclassifier__min_samples_split=0.025, randomforestclassifier__n_estimators=100 \n"
     ]
    }
   ],
   "source": [
    "estimator = pipeline.make_pipeline(\n",
    "    preprocessing.Imputer(strategy='mean'),\n",
    "    RandomForestClassifier(),\n",
    ")\n",
    "parameters = {\n",
    "    'randomforestclassifier__n_estimators': [ 20, 40, 60, 80, 100 ],\n",
    "    'randomforestclassifier__min_samples_split': [ 0.05, 0.025, 0.01, 0.005, ],\n",
    "}\n",
    "search = model_selection.GridSearchCV(estimator, parameters, cv=7, verbose=1)\n",
    "search.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluation\n",
    "print('Using parameters', search.best_params_)\n",
    "\n",
    "plot_learning_curve(search.best_estimator_, 'Learning curve', X_train, Y_train)\n",
    "\n",
    "Y_pred = search.best_estimator_.predict(X_test)\n",
    "print('Test set accuracy: %.2f%%' % (metrics.accuracy_score(Y_pred, Y_test)*100,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(estimator):\n",
    "    without_result = data['survived'].isnull()\n",
    "    d = data[without_result][data_columns]\n",
    "    \n",
    "    s = pandas.DataFrame({\n",
    "        'PassengerId': d.index,\n",
    "        'Survived': estimator.predict(d).astype('int'),\n",
    "    })\n",
    "    s.to_csv('submission.csv', index=False)\n",
    "    return s\n",
    "    \n",
    "make_submission(search.best_estimator_);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
