{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "\n",
    "import pandas\n",
    "import numpy\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import sklearn.ensemble\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "import sklearn.feature_selection\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a combined DataFrame, and a dictionary of {featuretype: columns}\n",
    "def load_data(filename):\n",
    "    def load_sheet(name):\n",
    "        df = file.parse(name)\n",
    "        if 'Index' in df.columns:\n",
    "            # we index based on row number\n",
    "            del df['Index']\n",
    "        else:\n",
    "            # remove duplicated labels\n",
    "            del df['Labels']\n",
    "        return df\n",
    "    \n",
    "    file = pandas.ExcelFile(filename)\n",
    "    dfs = { sheet: load_sheet(sheet) for sheet in file.sheet_names}\n",
    "    \n",
    "    # AMT is missing names for columns\n",
    "    combine = [dfs[k] for k in dfs.keys() if k not in ('AMT')]\n",
    "    \n",
    "    combined = dfs['AMT'].copy().add_suffix('-AMT')\n",
    "    combined = combined.join(combine, lsuffix='', rsuffix='')\n",
    "    \n",
    "    # TODO: there are also categories within each wavelet series\n",
    "    # separated with a _ or -\n",
    "    feature_categories = {}\n",
    "    for category, df in dfs.items():\n",
    "        columns = df.columns\n",
    "        feature_categories[category] = columns\n",
    "    \n",
    "    return combined, feature_categories\n",
    "\n",
    "fulldata, categories = load_data('DAT300 - CA 1_NEW.xlsx')\n",
    "assert fulldata.shape[0] == 120, fulldata.shape\n",
    "assert numpy.count_nonzero(fulldata.Labels.isnull()) == 0, numpy.count_nonzero(fulldata.Labels.isnull())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Target', 'AMT', 'WT_originals', 'WT-LLL', 'WT-LLH', 'WT_LHL', 'WT_LHH', 'LBP'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-AMT</th>\n",
       "      <th>2-AMT</th>\n",
       "      <th>3-AMT</th>\n",
       "      <th>4-AMT</th>\n",
       "      <th>5-AMT</th>\n",
       "      <th>6-AMT</th>\n",
       "      <th>7-AMT</th>\n",
       "      <th>8-AMT</th>\n",
       "      <th>9-AMT</th>\n",
       "      <th>10-AMT</th>\n",
       "      <th>...</th>\n",
       "      <th>lbp_24_(24,3)</th>\n",
       "      <th>lbp_25_(24,3)</th>\n",
       "      <th>lbp_2_(24,3)</th>\n",
       "      <th>lbp_3_(24,3)</th>\n",
       "      <th>lbp_4_(24,3)</th>\n",
       "      <th>lbp_5_(24,3)</th>\n",
       "      <th>lbp_6_(24,3)</th>\n",
       "      <th>lbp_7_(24,3)</th>\n",
       "      <th>lbp_8_(24,3)</th>\n",
       "      <th>lbp_9_(24,3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.55144</td>\n",
       "      <td>1.51980</td>\n",
       "      <td>1.45847</td>\n",
       "      <td>1.43940</td>\n",
       "      <td>1.43263</td>\n",
       "      <td>1.44893</td>\n",
       "      <td>1.50741</td>\n",
       "      <td>1.54977</td>\n",
       "      <td>1.59866</td>\n",
       "      <td>1.63075</td>\n",
       "      <td>...</td>\n",
       "      <td>53695</td>\n",
       "      <td>468638</td>\n",
       "      <td>17261</td>\n",
       "      <td>15439</td>\n",
       "      <td>18953</td>\n",
       "      <td>22857</td>\n",
       "      <td>24262</td>\n",
       "      <td>26894</td>\n",
       "      <td>27454</td>\n",
       "      <td>29276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51458</td>\n",
       "      <td>1.47539</td>\n",
       "      <td>1.45449</td>\n",
       "      <td>1.46195</td>\n",
       "      <td>1.44090</td>\n",
       "      <td>1.47846</td>\n",
       "      <td>1.51607</td>\n",
       "      <td>1.53459</td>\n",
       "      <td>1.51287</td>\n",
       "      <td>1.54192</td>\n",
       "      <td>...</td>\n",
       "      <td>53047</td>\n",
       "      <td>462418</td>\n",
       "      <td>16941</td>\n",
       "      <td>15294</td>\n",
       "      <td>18823</td>\n",
       "      <td>22369</td>\n",
       "      <td>24826</td>\n",
       "      <td>27250</td>\n",
       "      <td>28437</td>\n",
       "      <td>30374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.50565</td>\n",
       "      <td>1.46602</td>\n",
       "      <td>1.44400</td>\n",
       "      <td>1.45143</td>\n",
       "      <td>1.42508</td>\n",
       "      <td>1.41574</td>\n",
       "      <td>1.44243</td>\n",
       "      <td>1.47648</td>\n",
       "      <td>1.44198</td>\n",
       "      <td>1.45998</td>\n",
       "      <td>...</td>\n",
       "      <td>53917</td>\n",
       "      <td>469225</td>\n",
       "      <td>17328</td>\n",
       "      <td>15441</td>\n",
       "      <td>19056</td>\n",
       "      <td>22997</td>\n",
       "      <td>24702</td>\n",
       "      <td>26641</td>\n",
       "      <td>27585</td>\n",
       "      <td>29121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.53664</td>\n",
       "      <td>1.50323</td>\n",
       "      <td>1.46508</td>\n",
       "      <td>1.42571</td>\n",
       "      <td>1.43470</td>\n",
       "      <td>1.42078</td>\n",
       "      <td>1.44322</td>\n",
       "      <td>1.45240</td>\n",
       "      <td>1.46457</td>\n",
       "      <td>1.51837</td>\n",
       "      <td>...</td>\n",
       "      <td>53643</td>\n",
       "      <td>465916</td>\n",
       "      <td>16694</td>\n",
       "      <td>15318</td>\n",
       "      <td>18830</td>\n",
       "      <td>22634</td>\n",
       "      <td>24608</td>\n",
       "      <td>26706</td>\n",
       "      <td>27805</td>\n",
       "      <td>29507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.52808</td>\n",
       "      <td>1.47522</td>\n",
       "      <td>1.45618</td>\n",
       "      <td>1.37537</td>\n",
       "      <td>1.37561</td>\n",
       "      <td>1.39346</td>\n",
       "      <td>1.42378</td>\n",
       "      <td>1.46455</td>\n",
       "      <td>1.47553</td>\n",
       "      <td>1.46507</td>\n",
       "      <td>...</td>\n",
       "      <td>48987</td>\n",
       "      <td>456795</td>\n",
       "      <td>15882</td>\n",
       "      <td>14244</td>\n",
       "      <td>17120</td>\n",
       "      <td>20866</td>\n",
       "      <td>23471</td>\n",
       "      <td>26877</td>\n",
       "      <td>28607</td>\n",
       "      <td>31338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1426 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1-AMT    2-AMT    3-AMT    4-AMT    5-AMT    6-AMT    7-AMT    8-AMT  \\\n",
       "0  1.55144  1.51980  1.45847  1.43940  1.43263  1.44893  1.50741  1.54977   \n",
       "1  1.51458  1.47539  1.45449  1.46195  1.44090  1.47846  1.51607  1.53459   \n",
       "2  1.50565  1.46602  1.44400  1.45143  1.42508  1.41574  1.44243  1.47648   \n",
       "3  1.53664  1.50323  1.46508  1.42571  1.43470  1.42078  1.44322  1.45240   \n",
       "4  1.52808  1.47522  1.45618  1.37537  1.37561  1.39346  1.42378  1.46455   \n",
       "\n",
       "     9-AMT   10-AMT      ...       lbp_24_(24,3)  lbp_25_(24,3)  lbp_2_(24,3)  \\\n",
       "0  1.59866  1.63075      ...               53695         468638         17261   \n",
       "1  1.51287  1.54192      ...               53047         462418         16941   \n",
       "2  1.44198  1.45998      ...               53917         469225         17328   \n",
       "3  1.46457  1.51837      ...               53643         465916         16694   \n",
       "4  1.47553  1.46507      ...               48987         456795         15882   \n",
       "\n",
       "   lbp_3_(24,3)  lbp_4_(24,3)  lbp_5_(24,3)  lbp_6_(24,3)  lbp_7_(24,3)  \\\n",
       "0         15439         18953         22857         24262         26894   \n",
       "1         15294         18823         22369         24826         27250   \n",
       "2         15441         19056         22997         24702         26641   \n",
       "3         15318         18830         22634         24608         26706   \n",
       "4         14244         17120         20866         23471         26877   \n",
       "\n",
       "   lbp_8_(24,3)  lbp_9_(24,3)  \n",
       "0         27454         29276  \n",
       "1         28437         30374  \n",
       "2         27585         29121  \n",
       "3         27805         29507  \n",
       "4         28607         31338  \n",
       "\n",
       "[5 rows x 1426 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 1426)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_XY(data, feature_columns=None):\n",
    "    all_feature_columns = list(set(data.columns) - set(['Labels']))\n",
    "    \n",
    "    use = data[data.Labels.notna()]\n",
    "    X = use[all_feature_columns].astype(float)\n",
    "    if feature_columns is not None:\n",
    "        X = X.iloc[:,feature_columns]\n",
    "    y = use.Labels\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN = ( sklearn.neighbors.KNeighborsClassifier(), {\n",
    "       'n_neighbors': [1,2,3,4],\n",
    "})\n",
    "RandomForest = ( sklearn.ensemble.RandomForestClassifier(), {\n",
    "    'n_estimators': [10, 30, 100],\n",
    "    'min_samples_leaf': [0.01, 0.1],\n",
    "})\n",
    "Logistic = ( sklearn.linear_model.LogisticRegression(multi_class='ovr', solver='liblinear'),  {\n",
    "    'C': [ 0.75, 0.5, 0.25 ],\n",
    "})\n",
    "\n",
    "# TODO: add GBT\n",
    "# MAYBE: add SVM polynomial\n",
    "\n",
    "models = [\n",
    "    kNN,\n",
    "    RandomForest,\n",
    "    Logistic,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_candidate(dataset, cand, gridcv=5, n_tests=100, seed=0, evalcv=3):\n",
    "    model, params, features = cand\n",
    "\n",
    "    # Reduce to subset of features\n",
    "    X, y = get_XY(dataset, features)\n",
    "    X = sklearn.preprocessing.RobustScaler().fit_transform(X)\n",
    "    \n",
    "    # Decide hyperparameters\n",
    "    gridsearch_start = time.time()\n",
    "    grid = sklearn.model_selection.GridSearchCV(model, params, cv=gridcv,\n",
    "                                                iid=False, refit=True, return_train_score=True)\n",
    "    grid.fit(X, y)\n",
    "    estimator = grid.best_estimator_\n",
    "    \n",
    "    gridsearch_time = time.time() - gridsearch_start\n",
    "    \n",
    "    # Evaluate on a range of test-train splits\n",
    "    numpy.random.seed(seed)\n",
    "    test_scores = numpy.array([])\n",
    "    train_scores = numpy.array([])\n",
    "\n",
    "    evaluate_start = time.time()\n",
    "    for rng in numpy.random.randint(0, 1000, size=n_tests):\n",
    "        X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.4, random_state=rng)\n",
    "\n",
    "        estimator.fit(X_train, Y_train)\n",
    "\n",
    "        # FIXME: calculate score across whole test/trainset\n",
    "        test = sklearn.model_selection.cross_val_score(estimator, X_test, Y_test, cv=evalcv)\n",
    "        train = sklearn.model_selection.cross_val_score(estimator, X_train, Y_train, cv=evalcv)\n",
    "        \n",
    "        test_scores = numpy.concatenate([test_scores, test]) \n",
    "        train_scores = numpy.concatenate([train_scores, train])\n",
    "    evaluate_time =  time.time() - evaluate_start\n",
    "    \n",
    "    return test_scores, train_scores, grid.cv_results_, gridsearch_time, evaluate_time\n",
    "\n",
    "def test_evaluate_candidate():\n",
    "    all_features = None\n",
    "    candidate = (sklearn.ensemble.RandomForestClassifier(n_estimators=10), {}, all_features)\n",
    "    r = evaluate_candidate(fulldata, candidate, n_tests=10)\n",
    "    assert len(r) == 5\n",
    "                       \n",
    "test_evaluate_candidate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "\n",
    "### Random selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_candidates(models, feature_lengths, n_random=5, max_features=1425):\n",
    "    candidates = []\n",
    "    for n_features in feature_lengths:\n",
    "        random_features = numpy.random.choice(range(max_features), size=(n_random, n_features), replace=False)\n",
    "        for features in random_features:\n",
    "            for (m,p) in models:\n",
    "                candidates.append(( m, p, features, 'random' ))\n",
    "\n",
    "    return candidates\n",
    "random_candidates(models, (1,), 5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate feature scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_score_rf(X, y, n_reps=30):\n",
    "    importances = numpy.ndarray((n_reps, X.shape[1]))\n",
    "    # RF tends to ignore redundant features, so average over many runs\n",
    "    for i in range(0, n_reps):\n",
    "        rf = sklearn.ensemble.RandomForestClassifier(n_estimators=50, random_state=i)\n",
    "        rf.fit(X, y)\n",
    "        s = rf.feature_importances_\n",
    "        importances[i] = s\n",
    "        assert numpy.isclose(numpy.sum(s), 1.0), numpy.sum(s)\n",
    "    \n",
    "    return numpy.mean(importances, axis=0)\n",
    "\n",
    "def extract_feature_scores(X, y, scorers):\n",
    "    ret = []\n",
    "    X = sklearn.preprocessing.MinMaxScaler().fit_transform(X)\n",
    "    for f in scorers:\n",
    "        scores = numpy.array(f(X, y))\n",
    "        if scores.shape[0] == 2:\n",
    "            scores = scores[0] # drop p-values\n",
    "        # normalize it\n",
    "        scores = scores/scores.sum()\n",
    "        ret.append(scores)\n",
    "    return numpy.array(ret)\n",
    "\n",
    "def select_k_best(scores, n):\n",
    "    return numpy.argsort(scores)[:n]\n",
    "\n",
    "def univariate_candidates(models, features_length, scores):\n",
    "    candidates = []\n",
    "    for n_features in features_length:\n",
    "        \n",
    "        for (m,p) in models:\n",
    "            # individual scoring functions\n",
    "            for scores in feature_scores:\n",
    "                cand = ( m, p, select_k_best(scores, n_features), 'k-best' )\n",
    "                candidates.append(cand)\n",
    "\n",
    "            # combined univariate score\n",
    "            scores = numpy.mean(feature_scores, axis=0)\n",
    "            assert scores.shape[0] == 1425\n",
    "            candidates.append((m, p, select_k_best(scores, n_features), 'k-best-mean'))\n",
    "\n",
    "    return candidates\n",
    "\n",
    "feature_scorers = [\n",
    "    feature_score_rf,\n",
    "    sklearn.feature_selection.mutual_info_classif,\n",
    "    sklearn.feature_selection.f_classif,\n",
    "    sklearn.feature_selection.chi2,\n",
    "]\n",
    "feature_scores = extract_feature_scores(*get_XY(fulldata), feature_scorers)\n",
    "assert feature_scores.shape[1] == 1425\n",
    "univariate_candidates(models, (1,), feature_scores);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot feature scores, each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1425)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Forward Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "def sfs_candidates(dataset, models, features_length):\n",
    "    candidates = []\n",
    "    \n",
    "    estimators = {\n",
    "        #'RF': sklearn.ensemble.RandomForestClassifier(n_estimators=20),\n",
    "        'kNN1': sklearn.neighbors.KNeighborsClassifier(n_neighbors=1),\n",
    "        #'kNN2': sklearn.neighbors.KNeighborsClassifier(n_neighbors=2),\n",
    "    }\n",
    "    for name, estimator in estimators.items():\n",
    "        max_features = max(features_length)\n",
    "        sfs = SequentialFeatureSelector(estimator, k_features=max_features, forward=True, floating=False,\n",
    "                                        cv=5, scoring='accuracy')\n",
    "        X, y = get_XY(dataset)\n",
    "        sfs.fit(X, y)\n",
    "\n",
    "        # Also evaluate shorter combinations of the best K\n",
    "        for n_features in features_length:\n",
    "            features = sfs.k_feature_idx_[:n_features]\n",
    "    \n",
    "            for (m, p) in models:\n",
    "                candidates.append((m, p, features, 'sfs'))\n",
    "        \n",
    "    return candidates\n",
    "    \n",
    "sfs_candidates(fulldata, [], (2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_features_candidates(models):\n",
    "    candidates = []\n",
    "    for (m, p) in models:\n",
    "        candidates.append(( m, p, None, 'all'))\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_lengths = (1, 2, 3, 5)\n",
    "\n",
    "candidates = [] + \\\n",
    "    all_features_candidates(models) + \\\n",
    "    sfs_candidates(fulldata, models, feature_lengths) + \\\n",
    "    univariate_candidates(models, feature_lengths, feature_scores) + \\\n",
    "    random_candidates(models, feature_lengths, n_random=3)\n",
    "\n",
    "#numpy.random.shuffle(candidates)\n",
    "\n",
    "#for cand in candidates:\n",
    "#    print('cand', cand[2], type(cand[0]), cand[3])\n",
    "\n",
    "len(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.220787286758423 1.0318548679351807\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-8eea08597a34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcandidate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_candidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfulldata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_tests\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-13308ef38c5d>\u001b[0m in \u001b[0;36mevaluate_candidate\u001b[0;34m(dataset, cand, gridcv, n_tests, seed, evalcv)\u001b[0m\n\u001b[1;32m     10\u001b[0m     grid = sklearn.model_selection.GridSearchCV(model, params, cv=gridcv,\n\u001b[1;32m     11\u001b[0m                                                 iid=False, refit=True, return_train_score=True)\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    984\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 335\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    984\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    363\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for candidate in candidates:\n",
    "    selector = candidate[3] \n",
    "    r = evaluate_candidate(fulldata, candidate[:3], n_tests=10)\n",
    "    assert len(r) == 5, len(r)\n",
    "    print(r[3], r[4])\n",
    "    results.append((candidate, r, selector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_mean</th>\n",
       "      <th>test_std</th>\n",
       "      <th>train_mean</th>\n",
       "      <th>train_std</th>\n",
       "      <th>n_features</th>\n",
       "      <th>features</th>\n",
       "      <th>model</th>\n",
       "      <th>feature_selector</th>\n",
       "      <th>gridsearch_time</th>\n",
       "      <th>evaluation_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.856728</td>\n",
       "      <td>0.085710</td>\n",
       "      <td>0.912437</td>\n",
       "      <td>0.053595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>all</td>\n",
       "      <td>7.171826</td>\n",
       "      <td>8.300301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.804330</td>\n",
       "      <td>0.102859</td>\n",
       "      <td>0.861321</td>\n",
       "      <td>0.068962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>all</td>\n",
       "      <td>15.706465</td>\n",
       "      <td>28.781005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.676785</td>\n",
       "      <td>0.123152</td>\n",
       "      <td>0.762794</td>\n",
       "      <td>0.076915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>all</td>\n",
       "      <td>2.228999</td>\n",
       "      <td>1.015342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.590322</td>\n",
       "      <td>0.142925</td>\n",
       "      <td>0.597795</td>\n",
       "      <td>0.084432</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[651]</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>random</td>\n",
       "      <td>0.193654</td>\n",
       "      <td>0.477535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.570114</td>\n",
       "      <td>0.096419</td>\n",
       "      <td>0.585086</td>\n",
       "      <td>0.095850</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[651]</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>random</td>\n",
       "      <td>4.452227</td>\n",
       "      <td>2.245170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.563626</td>\n",
       "      <td>0.119677</td>\n",
       "      <td>0.596079</td>\n",
       "      <td>0.073031</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[368]</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>random</td>\n",
       "      <td>0.196882</td>\n",
       "      <td>0.478912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.555389</td>\n",
       "      <td>0.091202</td>\n",
       "      <td>0.551425</td>\n",
       "      <td>0.074966</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[368]</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>random</td>\n",
       "      <td>4.338469</td>\n",
       "      <td>2.239923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.513516</td>\n",
       "      <td>0.103008</td>\n",
       "      <td>0.564326</td>\n",
       "      <td>0.103839</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[1121, 551]</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>random</td>\n",
       "      <td>0.194291</td>\n",
       "      <td>0.478662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.510922</td>\n",
       "      <td>0.081455</td>\n",
       "      <td>0.587507</td>\n",
       "      <td>0.078639</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[1121, 551]</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>random</td>\n",
       "      <td>4.560875</td>\n",
       "      <td>20.380141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.487034</td>\n",
       "      <td>0.086306</td>\n",
       "      <td>0.519009</td>\n",
       "      <td>0.066071</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[638]</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>random</td>\n",
       "      <td>4.629830</td>\n",
       "      <td>18.666825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test_mean  test_std  train_mean  train_std  n_features     features  \\\n",
       "1    0.856728  0.085710    0.912437   0.053595         NaN         None   \n",
       "2    0.804330  0.102859    0.861321   0.068962         NaN         None   \n",
       "0    0.676785  0.123152    0.762794   0.076915         NaN         None   \n",
       "9    0.590322  0.142925    0.597795   0.084432         1.0        [651]   \n",
       "10   0.570114  0.096419    0.585086   0.095850         1.0        [651]   \n",
       "3    0.563626  0.119677    0.596079   0.073031         1.0        [368]   \n",
       "4    0.555389  0.091202    0.551425   0.074966         1.0        [368]   \n",
       "12   0.513516  0.103008    0.564326   0.103839         2.0  [1121, 551]   \n",
       "13   0.510922  0.081455    0.587507   0.078639         2.0  [1121, 551]   \n",
       "7    0.487034  0.086306    0.519009   0.066071         1.0        [638]   \n",
       "\n",
       "                     model feature_selector  gridsearch_time  evaluation_time  \n",
       "1   RandomForestClassifier              all         7.171826         8.300301  \n",
       "2       LogisticRegression              all        15.706465        28.781005  \n",
       "0     KNeighborsClassifier              all         2.228999         1.015342  \n",
       "9     KNeighborsClassifier           random         0.193654         0.477535  \n",
       "10  RandomForestClassifier           random         4.452227         2.245170  \n",
       "3     KNeighborsClassifier           random         0.196882         0.478912  \n",
       "4   RandomForestClassifier           random         4.338469         2.239923  \n",
       "12    KNeighborsClassifier           random         0.194291         0.478662  \n",
       "13  RandomForestClassifier           random         4.560875        20.380141  \n",
       "7   RandomForestClassifier           random         4.629830        18.666825  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores = numpy.array([r[1][0] for r in results])\n",
    "train_scores = numpy.array([r[1][1] for r in results])\n",
    "\n",
    "def n_features(r):\n",
    "    f = r[0][2]\n",
    "    if f is None:\n",
    "        return None\n",
    "    else:\n",
    "        return len(f)\n",
    "\n",
    "df = pandas.DataFrame({\n",
    "    'test_mean': test_scores.mean(axis=1),\n",
    "    'test_std': test_scores.std(axis=1),\n",
    "    'train_mean': train_scores.mean(axis=1),\n",
    "    'train_std': train_scores.std(axis=1),\n",
    "    'n_features': [ n_features(r) for r in results ],\n",
    "    'features': [ r[0][2] for r in results ],\n",
    "    'model': [ str(type(r[0][0]).__name__) for r in results ],\n",
    "    'feature_selector': [ r[2] for r in results ],\n",
    "    'gridsearch_time': [ r[1][3] for r in results ],\n",
    "    'evaluation_time': [ r[1][4] for r in results ],\n",
    "})\n",
    "df.sort_values(by='test_mean', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f952b19c5f8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f952b0a9710>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f952aee9a20>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f952af13d30>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist('test_mean', bins=10, by=['model'], figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
