{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "\n",
    "import pandas\n",
    "import numpy\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import sklearn.ensemble\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "import sklearn.feature_selection\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a combined DataFrame, and a dictionary of {featuretype: columns}\n",
    "def load_data(filename):\n",
    "    def load_sheet(name):\n",
    "        df = file.parse(name)\n",
    "        if 'Index' in df.columns:\n",
    "            # we index based on row number\n",
    "            del df['Index']\n",
    "        else:\n",
    "            # remove duplicated labels\n",
    "            del df['Labels']\n",
    "        return df\n",
    "    \n",
    "    file = pandas.ExcelFile(filename)\n",
    "    dfs = { sheet: load_sheet(sheet) for sheet in file.sheet_names}\n",
    "    \n",
    "    # AMT is missing names for columns\n",
    "    combine = [dfs[k] for k in dfs.keys() if k not in ('AMT')]\n",
    "    \n",
    "    combined = dfs['AMT'].copy().add_suffix('-AMT')\n",
    "    combined = combined.join(combine, lsuffix='', rsuffix='')\n",
    "    \n",
    "    # TODO: there are also categories within each wavelet series\n",
    "    # separated with a _ or -\n",
    "    feature_categories = {}\n",
    "    for category, df in dfs.items():\n",
    "        columns = df.columns\n",
    "        feature_categories[category] = columns\n",
    "    \n",
    "    return combined, feature_categories\n",
    "\n",
    "fulldata, categories = load_data('DAT300 - CA 1_NEW.xlsx')\n",
    "assert fulldata.shape[0] == 120, fulldata.shape\n",
    "assert numpy.count_nonzero(fulldata.Labels.isnull()) == 0, numpy.count_nonzero(fulldata.Labels.isnull())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Target', 'AMT', 'WT_originals', 'WT-LLL', 'WT-LLH', 'WT_LHL', 'WT_LHH', 'LBP'])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-AMT</th>\n",
       "      <th>2-AMT</th>\n",
       "      <th>3-AMT</th>\n",
       "      <th>4-AMT</th>\n",
       "      <th>5-AMT</th>\n",
       "      <th>6-AMT</th>\n",
       "      <th>7-AMT</th>\n",
       "      <th>8-AMT</th>\n",
       "      <th>9-AMT</th>\n",
       "      <th>10-AMT</th>\n",
       "      <th>...</th>\n",
       "      <th>lbp_24_(24,3)</th>\n",
       "      <th>lbp_25_(24,3)</th>\n",
       "      <th>lbp_2_(24,3)</th>\n",
       "      <th>lbp_3_(24,3)</th>\n",
       "      <th>lbp_4_(24,3)</th>\n",
       "      <th>lbp_5_(24,3)</th>\n",
       "      <th>lbp_6_(24,3)</th>\n",
       "      <th>lbp_7_(24,3)</th>\n",
       "      <th>lbp_8_(24,3)</th>\n",
       "      <th>lbp_9_(24,3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.55144</td>\n",
       "      <td>1.51980</td>\n",
       "      <td>1.45847</td>\n",
       "      <td>1.43940</td>\n",
       "      <td>1.43263</td>\n",
       "      <td>1.44893</td>\n",
       "      <td>1.50741</td>\n",
       "      <td>1.54977</td>\n",
       "      <td>1.59866</td>\n",
       "      <td>1.63075</td>\n",
       "      <td>...</td>\n",
       "      <td>53695</td>\n",
       "      <td>468638</td>\n",
       "      <td>17261</td>\n",
       "      <td>15439</td>\n",
       "      <td>18953</td>\n",
       "      <td>22857</td>\n",
       "      <td>24262</td>\n",
       "      <td>26894</td>\n",
       "      <td>27454</td>\n",
       "      <td>29276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51458</td>\n",
       "      <td>1.47539</td>\n",
       "      <td>1.45449</td>\n",
       "      <td>1.46195</td>\n",
       "      <td>1.44090</td>\n",
       "      <td>1.47846</td>\n",
       "      <td>1.51607</td>\n",
       "      <td>1.53459</td>\n",
       "      <td>1.51287</td>\n",
       "      <td>1.54192</td>\n",
       "      <td>...</td>\n",
       "      <td>53047</td>\n",
       "      <td>462418</td>\n",
       "      <td>16941</td>\n",
       "      <td>15294</td>\n",
       "      <td>18823</td>\n",
       "      <td>22369</td>\n",
       "      <td>24826</td>\n",
       "      <td>27250</td>\n",
       "      <td>28437</td>\n",
       "      <td>30374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.50565</td>\n",
       "      <td>1.46602</td>\n",
       "      <td>1.44400</td>\n",
       "      <td>1.45143</td>\n",
       "      <td>1.42508</td>\n",
       "      <td>1.41574</td>\n",
       "      <td>1.44243</td>\n",
       "      <td>1.47648</td>\n",
       "      <td>1.44198</td>\n",
       "      <td>1.45998</td>\n",
       "      <td>...</td>\n",
       "      <td>53917</td>\n",
       "      <td>469225</td>\n",
       "      <td>17328</td>\n",
       "      <td>15441</td>\n",
       "      <td>19056</td>\n",
       "      <td>22997</td>\n",
       "      <td>24702</td>\n",
       "      <td>26641</td>\n",
       "      <td>27585</td>\n",
       "      <td>29121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.53664</td>\n",
       "      <td>1.50323</td>\n",
       "      <td>1.46508</td>\n",
       "      <td>1.42571</td>\n",
       "      <td>1.43470</td>\n",
       "      <td>1.42078</td>\n",
       "      <td>1.44322</td>\n",
       "      <td>1.45240</td>\n",
       "      <td>1.46457</td>\n",
       "      <td>1.51837</td>\n",
       "      <td>...</td>\n",
       "      <td>53643</td>\n",
       "      <td>465916</td>\n",
       "      <td>16694</td>\n",
       "      <td>15318</td>\n",
       "      <td>18830</td>\n",
       "      <td>22634</td>\n",
       "      <td>24608</td>\n",
       "      <td>26706</td>\n",
       "      <td>27805</td>\n",
       "      <td>29507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.52808</td>\n",
       "      <td>1.47522</td>\n",
       "      <td>1.45618</td>\n",
       "      <td>1.37537</td>\n",
       "      <td>1.37561</td>\n",
       "      <td>1.39346</td>\n",
       "      <td>1.42378</td>\n",
       "      <td>1.46455</td>\n",
       "      <td>1.47553</td>\n",
       "      <td>1.46507</td>\n",
       "      <td>...</td>\n",
       "      <td>48987</td>\n",
       "      <td>456795</td>\n",
       "      <td>15882</td>\n",
       "      <td>14244</td>\n",
       "      <td>17120</td>\n",
       "      <td>20866</td>\n",
       "      <td>23471</td>\n",
       "      <td>26877</td>\n",
       "      <td>28607</td>\n",
       "      <td>31338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1426 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1-AMT    2-AMT    3-AMT    4-AMT    5-AMT    6-AMT    7-AMT    8-AMT  \\\n",
       "0  1.55144  1.51980  1.45847  1.43940  1.43263  1.44893  1.50741  1.54977   \n",
       "1  1.51458  1.47539  1.45449  1.46195  1.44090  1.47846  1.51607  1.53459   \n",
       "2  1.50565  1.46602  1.44400  1.45143  1.42508  1.41574  1.44243  1.47648   \n",
       "3  1.53664  1.50323  1.46508  1.42571  1.43470  1.42078  1.44322  1.45240   \n",
       "4  1.52808  1.47522  1.45618  1.37537  1.37561  1.39346  1.42378  1.46455   \n",
       "\n",
       "     9-AMT   10-AMT      ...       lbp_24_(24,3)  lbp_25_(24,3)  lbp_2_(24,3)  \\\n",
       "0  1.59866  1.63075      ...               53695         468638         17261   \n",
       "1  1.51287  1.54192      ...               53047         462418         16941   \n",
       "2  1.44198  1.45998      ...               53917         469225         17328   \n",
       "3  1.46457  1.51837      ...               53643         465916         16694   \n",
       "4  1.47553  1.46507      ...               48987         456795         15882   \n",
       "\n",
       "   lbp_3_(24,3)  lbp_4_(24,3)  lbp_5_(24,3)  lbp_6_(24,3)  lbp_7_(24,3)  \\\n",
       "0         15439         18953         22857         24262         26894   \n",
       "1         15294         18823         22369         24826         27250   \n",
       "2         15441         19056         22997         24702         26641   \n",
       "3         15318         18830         22634         24608         26706   \n",
       "4         14244         17120         20866         23471         26877   \n",
       "\n",
       "   lbp_8_(24,3)  lbp_9_(24,3)  \n",
       "0         27454         29276  \n",
       "1         28437         30374  \n",
       "2         27585         29121  \n",
       "3         27805         29507  \n",
       "4         28607         31338  \n",
       "\n",
       "[5 rows x 1426 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 1426)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_XY(data, feature_columns=None):\n",
    "    all_feature_columns = list(set(data.columns) - set(['Labels']))\n",
    "    \n",
    "    use = data[data.Labels.notna()]\n",
    "    X = use[all_feature_columns].astype(float)\n",
    "    if feature_columns is not None:\n",
    "        X = X.iloc[:,feature_columns]\n",
    "    y = use.Labels\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN = ( sklearn.neighbors.KNeighborsClassifier(), {\n",
    "       'n_neighbors': [1,2,3,4],\n",
    "})\n",
    "RandomForest = ( sklearn.ensemble.RandomForestClassifier(), {\n",
    "    'n_estimators': [10, 30, 100],\n",
    "    'min_samples_leaf': [0.01, 0.1],\n",
    "})\n",
    "Logistic = ( sklearn.linear_model.LogisticRegression(multi_class='ovr', solver='liblinear'),  {\n",
    "    'C': [ 0.75, 0.5, 0.25 ],\n",
    "})\n",
    "\n",
    "# TODO: add GBT\n",
    "# MAYBE: add SVM polynomial\n",
    "\n",
    "models = [\n",
    "    kNN,\n",
    "    RandomForest,\n",
    "    Logistic,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_candidate(dataset, cand, gridcv=5, n_tests=100, seed=0, evalcv=3):\n",
    "    model, params, features = cand\n",
    "\n",
    "    # Reduce to subset of features\n",
    "    X, y = get_XY(dataset, features)\n",
    "    X = sklearn.preprocessing.RobustScaler().fit_transform(X)\n",
    "    \n",
    "    # Decide hyperparameters\n",
    "    gridsearch_start = time.time()\n",
    "    grid = sklearn.model_selection.GridSearchCV(model, params, cv=gridcv,\n",
    "                                                iid=False, refit=True, return_train_score=True)\n",
    "    grid.fit(X, y)\n",
    "    estimator = grid.best_estimator_\n",
    "    \n",
    "    gridsearch_time = time.time() - gridsearch_start\n",
    "    \n",
    "    # Evaluate on a range of test-train splits\n",
    "    numpy.random.seed(seed)\n",
    "    test_scores = numpy.array([])\n",
    "    train_scores = numpy.array([])\n",
    "\n",
    "    evaluate_start = time.time()\n",
    "    for rng in numpy.random.randint(0, 1000, size=n_tests):\n",
    "        X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.4, random_state=rng)\n",
    "\n",
    "        estimator.fit(X_train, Y_train)\n",
    "\n",
    "        # FIXME: calculate score across whole test/trainset\n",
    "        test = sklearn.model_selection.cross_val_score(estimator, X_test, Y_test, cv=evalcv)\n",
    "        train = sklearn.model_selection.cross_val_score(estimator, X_train, Y_train, cv=evalcv)\n",
    "        \n",
    "        test_scores = numpy.concatenate([test_scores, test]) \n",
    "        train_scores = numpy.concatenate([train_scores, train])\n",
    "    evaluate_time =  time.time() - evaluate_start\n",
    "    \n",
    "    return test_scores, train_scores, grid.cv_results_, gridsearch_time, evaluate_time\n",
    "\n",
    "def test_evaluate_candidate():\n",
    "    all_features = None\n",
    "    candidate = (sklearn.ensemble.RandomForestClassifier(n_estimators=10), {}, all_features)\n",
    "    r = evaluate_candidate(fulldata, candidate, n_tests=10)\n",
    "    assert len(r) == 5\n",
    "                       \n",
    "test_evaluate_candidate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "\n",
    "### Random selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_candidates(models, feature_lengths, n_random=5, max_features=1425):\n",
    "    candidates = []\n",
    "    for n_features in feature_lengths:\n",
    "        random_features = numpy.random.choice(range(max_features), size=(n_random, n_features), replace=False)\n",
    "        for features in random_features:\n",
    "            for (m,p) in models:\n",
    "                candidates.append(( m, p, features, 'random' ))\n",
    "\n",
    "    return candidates\n",
    "random_candidates(models, (1,), 5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate feature scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_score_rf(X, y, n_reps=30):\n",
    "    importances = numpy.ndarray((n_reps, X.shape[1]))\n",
    "    # RF tends to ignore redundant features, so average over many runs\n",
    "    for i in range(0, n_reps):\n",
    "        rf = sklearn.ensemble.RandomForestClassifier(n_estimators=50, random_state=i)\n",
    "        rf.fit(X, y)\n",
    "        s = rf.feature_importances_\n",
    "        importances[i] = s\n",
    "        assert numpy.isclose(numpy.sum(s), 1.0), numpy.sum(s)\n",
    "    \n",
    "    return numpy.mean(importances, axis=0)\n",
    "\n",
    "def extract_feature_scores(X, y, scorers):\n",
    "    ret = []\n",
    "    X = sklearn.preprocessing.MinMaxScaler().fit_transform(X)\n",
    "    for f in scorers:\n",
    "        scores = numpy.array(f(X, y))\n",
    "        if scores.shape[0] == 2:\n",
    "            scores = scores[0] # drop p-values\n",
    "        # normalize it\n",
    "        scores = scores/scores.sum()\n",
    "        ret.append(scores)\n",
    "    return numpy.array(ret)\n",
    "\n",
    "def select_k_best(scores, n):\n",
    "    return numpy.argsort(scores)[:n]\n",
    "\n",
    "def univariate_candidates(models, features_length, scores):\n",
    "    candidates = []\n",
    "    for n_features in features_length:\n",
    "        \n",
    "        for (m,p) in models:\n",
    "            # individual scoring functions\n",
    "            for scores in feature_scores:\n",
    "                cand = ( m, p, select_k_best(scores, n_features), 'k-best' )\n",
    "                candidates.append(cand)\n",
    "\n",
    "            # combined univariate score\n",
    "            scores = numpy.mean(feature_scores, axis=0)\n",
    "            assert scores.shape[0] == 1425\n",
    "            candidates.append((m, p, select_k_best(scores, n_features), 'k-best-mean'))\n",
    "\n",
    "    return candidates\n",
    "\n",
    "feature_scorers = [\n",
    "    feature_score_rf,\n",
    "    sklearn.feature_selection.mutual_info_classif,\n",
    "    sklearn.feature_selection.f_classif,\n",
    "    sklearn.feature_selection.chi2,\n",
    "]\n",
    "feature_scores = extract_feature_scores(*get_XY(fulldata), feature_scorers)\n",
    "assert feature_scores.shape[1] == 1425\n",
    "univariate_candidates(models, (1,), feature_scores);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot feature scores, each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1425)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_features_candidates(models):\n",
    "    candidates = []\n",
    "    for (m, p) in models:\n",
    "        candidates.append(( m, p, None, 'all'))\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: implement SFS\n",
    "# TODO: add baseline candidates (all features)\n",
    "\n",
    "feature_lengths = (1, 2, 3, 5)\n",
    "\n",
    "candidates = [] + \\\n",
    "    all_features_candidates(models) + \\\n",
    "    random_candidates(models, feature_lengths, n_random=3) + \\\n",
    "    univariate_candidates(models, feature_lengths, feature_scores)\n",
    "\n",
    "#numpy.random.shuffle(candidates)\n",
    "\n",
    "#for cand in candidates:\n",
    "#    print('cand', cand[2], type(cand[0]), cand[3])\n",
    "\n",
    "len(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-220-70ba8cedb0d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcandidate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_candidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfulldata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_tests\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-208-13308ef38c5d>\u001b[0m in \u001b[0;36mevaluate_candidate\u001b[0;34m(dataset, cand, gridcv, n_tests, seed, evalcv)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# FIXME: calculate score across whole test/trainset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevalcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevalcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 240\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    984\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 tree = self._make_estimator(append=False,\n\u001b[0;32m--> 321\u001b[0;31m                                             random_state=random_state)\n\u001b[0m\u001b[1;32m    322\u001b[0m                 \u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/ensemble/base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[0;34m(self, append, random_state)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         estimator.set_params(**dict((p, getattr(self, p))\n\u001b[0;32m--> 128\u001b[0;31m                                     for p in self.estimator_params))\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# Simple optimization to gain speed (inspect is slow)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mvalid_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mnested_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# grouped by prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \"\"\"\n\u001b[1;32m    180\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_get_param_names\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;31m# introspect the constructor arguments to find the model parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# to represent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0minit_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         parameters = [p for p in init_signature.parameters.values()\n",
      "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3069\u001b[0m     \u001b[0;34m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3070\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mSignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mfrom_callable\u001b[0;34m(cls, obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   2818\u001b[0m         \u001b[0;34m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2819\u001b[0m         return _signature_from_callable(obj, sigcls=cls,\n\u001b[0;32m-> 2820\u001b[0;31m                                         follow_wrapper_chains=follow_wrapped)\n\u001b[0m\u001b[1;32m   2821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2822\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[1;32m   2275\u001b[0m         \u001b[0;31m# If it's a pure Python function, or an object that is duck type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2276\u001b[0m         \u001b[0;31m# of a Python function (Cython functions, for instance), then:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_signature_from_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2279\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_signature_is_builtin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36m_signature_from_function\u001b[0;34m(cls, func)\u001b[0m\n\u001b[1;32m   2152\u001b[0m         parameters.append(Parameter(name, annotation=annotation,\n\u001b[1;32m   2153\u001b[0m                                     \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_POSITIONAL_OR_KEYWORD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2154\u001b[0;31m                                     default=defaults[offset]))\n\u001b[0m\u001b[1;32m   2155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m     \u001b[0;31m# *args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, kind, default, annotation)\u001b[0m\n\u001b[1;32m   2474\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name is a required attribute for Parameter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2476\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2477\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'name must be a str, not a {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2478\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for candidate in candidates:\n",
    "    selector = candidate[3] \n",
    "    r = evaluate_candidate(fulldata, candidate[:3], n_tests=10)\n",
    "    assert len(r) == 5, len(r)\n",
    "    results.append((candidate, r, selector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_mean</th>\n",
       "      <th>test_std</th>\n",
       "      <th>train_mean</th>\n",
       "      <th>train_std</th>\n",
       "      <th>n_features</th>\n",
       "      <th>features</th>\n",
       "      <th>model</th>\n",
       "      <th>feature_selector</th>\n",
       "      <th>gridsearch_time</th>\n",
       "      <th>evaluation_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.856728</td>\n",
       "      <td>0.085710</td>\n",
       "      <td>0.912437</td>\n",
       "      <td>0.053595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>all</td>\n",
       "      <td>7.171826</td>\n",
       "      <td>8.300301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.804330</td>\n",
       "      <td>0.102859</td>\n",
       "      <td>0.861321</td>\n",
       "      <td>0.068962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>all</td>\n",
       "      <td>15.706465</td>\n",
       "      <td>28.781005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.676785</td>\n",
       "      <td>0.123152</td>\n",
       "      <td>0.762794</td>\n",
       "      <td>0.076915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>all</td>\n",
       "      <td>2.228999</td>\n",
       "      <td>1.015342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.590322</td>\n",
       "      <td>0.142925</td>\n",
       "      <td>0.597795</td>\n",
       "      <td>0.084432</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[651]</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>random</td>\n",
       "      <td>0.193654</td>\n",
       "      <td>0.477535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.570114</td>\n",
       "      <td>0.096419</td>\n",
       "      <td>0.585086</td>\n",
       "      <td>0.095850</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[651]</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>random</td>\n",
       "      <td>4.452227</td>\n",
       "      <td>2.245170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.563626</td>\n",
       "      <td>0.119677</td>\n",
       "      <td>0.596079</td>\n",
       "      <td>0.073031</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[368]</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>random</td>\n",
       "      <td>0.196882</td>\n",
       "      <td>0.478912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.555389</td>\n",
       "      <td>0.091202</td>\n",
       "      <td>0.551425</td>\n",
       "      <td>0.074966</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[368]</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>random</td>\n",
       "      <td>4.338469</td>\n",
       "      <td>2.239923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.513516</td>\n",
       "      <td>0.103008</td>\n",
       "      <td>0.564326</td>\n",
       "      <td>0.103839</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[1121, 551]</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>random</td>\n",
       "      <td>0.194291</td>\n",
       "      <td>0.478662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.510922</td>\n",
       "      <td>0.081455</td>\n",
       "      <td>0.587507</td>\n",
       "      <td>0.078639</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[1121, 551]</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>random</td>\n",
       "      <td>4.560875</td>\n",
       "      <td>20.380141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.487034</td>\n",
       "      <td>0.086306</td>\n",
       "      <td>0.519009</td>\n",
       "      <td>0.066071</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[638]</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>random</td>\n",
       "      <td>4.629830</td>\n",
       "      <td>18.666825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test_mean  test_std  train_mean  train_std  n_features     features  \\\n",
       "1    0.856728  0.085710    0.912437   0.053595         NaN         None   \n",
       "2    0.804330  0.102859    0.861321   0.068962         NaN         None   \n",
       "0    0.676785  0.123152    0.762794   0.076915         NaN         None   \n",
       "9    0.590322  0.142925    0.597795   0.084432         1.0        [651]   \n",
       "10   0.570114  0.096419    0.585086   0.095850         1.0        [651]   \n",
       "3    0.563626  0.119677    0.596079   0.073031         1.0        [368]   \n",
       "4    0.555389  0.091202    0.551425   0.074966         1.0        [368]   \n",
       "12   0.513516  0.103008    0.564326   0.103839         2.0  [1121, 551]   \n",
       "13   0.510922  0.081455    0.587507   0.078639         2.0  [1121, 551]   \n",
       "7    0.487034  0.086306    0.519009   0.066071         1.0        [638]   \n",
       "\n",
       "                     model feature_selector  gridsearch_time  evaluation_time  \n",
       "1   RandomForestClassifier              all         7.171826         8.300301  \n",
       "2       LogisticRegression              all        15.706465        28.781005  \n",
       "0     KNeighborsClassifier              all         2.228999         1.015342  \n",
       "9     KNeighborsClassifier           random         0.193654         0.477535  \n",
       "10  RandomForestClassifier           random         4.452227         2.245170  \n",
       "3     KNeighborsClassifier           random         0.196882         0.478912  \n",
       "4   RandomForestClassifier           random         4.338469         2.239923  \n",
       "12    KNeighborsClassifier           random         0.194291         0.478662  \n",
       "13  RandomForestClassifier           random         4.560875        20.380141  \n",
       "7   RandomForestClassifier           random         4.629830        18.666825  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores = numpy.array([r[1][0] for r in results])\n",
    "train_scores = numpy.array([r[1][1] for r in results])\n",
    "\n",
    "def n_features(r):\n",
    "    f = r[0][2]\n",
    "    if f is None:\n",
    "        return None\n",
    "    else:\n",
    "        return len(f)\n",
    "\n",
    "df = pandas.DataFrame({\n",
    "    'test_mean': test_scores.mean(axis=1),\n",
    "    'test_std': test_scores.std(axis=1),\n",
    "    'train_mean': train_scores.mean(axis=1),\n",
    "    'train_std': train_scores.std(axis=1),\n",
    "    'n_features': [ n_features(r) for r in results ],\n",
    "    'features': [ r[0][2] for r in results ],\n",
    "    'model': [ str(type(r[0][0]).__name__) for r in results ],\n",
    "    'feature_selector': [ r[2] for r in results ],\n",
    "    'gridsearch_time': [ r[1][3] for r in results ],\n",
    "    'evaluation_time': [ r[1][4] for r in results ],\n",
    "})\n",
    "df.sort_values(by='test_mean', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f952bb78c18>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f952ba23748>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f952b9c2d68>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f952b972400>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist('test_mean', bins=20, by=['model', 'feature_selector'], figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
